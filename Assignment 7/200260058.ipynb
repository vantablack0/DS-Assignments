{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9e7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c48faa",
   "metadata": {},
   "source": [
    "# Assignment 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10561b39",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f63c6aa",
   "metadata": {},
   "source": [
    "#### a) Dimension Reduction. The input variable is the grades of the student for the 50 courses and the output variable is the array of 5 numbers obtained.\n",
    "#### b) Clustering. The input variable is their performance in various courses and extra-cirricular activities and the output variable is the unspecified personality class created by the clusters.\n",
    "#### c) Regression. The input variable is their performance in various courses, extra-curricular activities, and their first job type and the output variable is their Salary.\n",
    "#### d) Classification. The input variable is  performance in various courses and extra-curricular activities and the output variable is the Job profile or the type of job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1406d1e2",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf08ea",
   "metadata": {},
   "source": [
    "### 1) SVM-C with Gaussian kernel (Classification):\n",
    "#### a) Target Output Variable: One-hot or Integer\n",
    "#### b) Parameters: Class weights, class labels, intercept, Number of features seen during fit, support vectors, number of support vectors for each class\n",
    "#### c) Hyper-parameters: Regularization parameter, gamma(kernel coefficient), shrinking heuristic and tolerance\n",
    "#### d) Defining: svc = SVC() . Training: svc.fit(X,y) . Testing: svc.predict(X)\n",
    "\n",
    "### 2) SVM-R with Gaussian kernel (Regression):\n",
    "#### a) Target Output Variable: Floating point or Integer\n",
    "#### b) Parameters: Class weights, class labels, intercept, Number of features seen during fit, support vectors, number of support vectors for each class\n",
    "#### c) Hyper-parameters: Regularization parameter, gamma(kernel coefficient), Epsilon, shrinking heuristic and tolerance\n",
    "#### d) Defining: svr = SVR() . Training: svr.fit(X,y) . Testing: svr.predict(X)\n",
    "\n",
    "### 3) NN with one hidden layer (Classification):\n",
    "#### a) Target Output Variable: Integer or One-hot\n",
    "#### b) Parameters: Loss, best loss, loss curve, number of training samples, coefficients, intercepts, number of iterations and number of outputs\n",
    "#### c) Hyper-parameters: Activation function, solver for weight optimization, alpha, learning rate, tolerance, shuffle and maximum number of iterations.\n",
    "#### d) Defining: NNC = MLPClassifier() . Training: NNC.fit(X,y) . Testing: NNC.predict(X)\n",
    "\n",
    "### 4) NN with one hidden layer (Regression):\n",
    "#### a) Target Output Variable: Floating point or Integer\n",
    "#### b) Parameters: Loss, best loss, loss curve, number of training samples, coefficients, intercepts, number of iterations and number of outputs\n",
    "#### c) Hyper-parameters: Activation function, solver for weight optimization, alpha, learning rate, tolerance, shuffle and maximum number of iterations.\n",
    "#### d) Defining: NNR = MLPRegressor() . Training: NNR.fit(X,y) . Testing: NNR.predict(X)\n",
    "\n",
    "### 5) Random Forest (Classification):\n",
    "#### a) Target Output Variable: Integer or One-hot\n",
    "#### b) Parameters: Base Estimator, estimators, number of features, number of outputs and score of the training dataset obtained using an out-of-bag estimate\n",
    "#### c) Hyper-parameters: number of trees in the forest, criterion: {“gini”, “entropy”}, maximum depth of a tree, minimum number of samples required to split an internal node, minimum smaples required to be a leaf node, maximum features and maximum leaf nodes.\n",
    "#### d) Defining: rfc = RandomForestClassifier() . Training: rfc.fit(X,y) . Testing: rfc.predict(X)\n",
    "\n",
    "### 6) Random Forest (Regression):\n",
    "#### a) Target Output Variable: Integer or Floating Point\n",
    "#### b) Parameters: Base Estimator, estimators, number of features, number of outputs and score of the training dataset obtained using an out-of-bag estimate\n",
    "#### c) Hyper-parameters: number of trees in the forest, criterion : {“squared_error”, “mse”, “absolute_error”, “poisson”}, maximum depth of a tree, minimum number of samples required to split an internal node, minimum smaples required to be a leaf node, maximum features and maximum leaf nodes.\n",
    "#### d) Defining: rfr = RandomForestRegressor() . Training: rfr.fit(X,y) . Testing: rfr.predict(X)\n",
    "\n",
    "### 7) K-means (Clustering):\n",
    "#### a) Target Output Variable: Integer or One-hot \n",
    "#### b) Parameters: Cluster centers, labels, inertia, number of iterations run and number of features seen during fit\n",
    "#### c) Hyper-parameters: Number of clusters to form/ number of centroids, number of iterations, tolerance and algorithm : {“auto”, “full”, “elkan”}.\n",
    "#### d) Defining: kmean = KMeans() . Training: kmean.fit(X,y) . Testing: kmean.predict(X)\n",
    "\n",
    "### 8) DBSCAN (Clustering):\n",
    "#### a) Target Output Variable: Integer or One-hot \n",
    "#### b) Parameters: Indices of core samples, copy of each core sample found by training, labels and number of features\n",
    "#### c) Hyper-parameters: eps (The maximum distance between two samples for one to be considered as in the neighborhood of the other) , minimum number of samples, metric, algorithm:{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’} and leaf size\n",
    "#### d) Defining: dbs = DBSCAN() . Training: dbs.fit(X,y) . Testing: dbs.fit_predict(X)\n",
    "\n",
    "### 9) PCA (Dimenstion Reduction):\n",
    "#### a) Target Output Variable: Matrix of inputs with reduced dimensions \n",
    "#### b) Parameters: Components, explained variance, singular values, mean, number of feaures, number of components, number of features and number of samples\n",
    "#### c) Hyper-parameters: Number of components to keep, svd_solver : {‘auto’, ‘full’, ‘arpack’, ‘randomized’}, tolerance and iterated power.\n",
    "#### d) Defining: pca = PCA() . Training: pca.fit_transform(X,y) . Testing: pca.get_covariance(X)\n",
    "\n",
    "### 10) Kernel PCA (Dimenstion Reduction):\n",
    "#### a) Target Output Variable: Matrix of inputs with reduced dimensions \n",
    "#### b) Parameters: eigenvalues, eigenvectors, X transformed fit and number of features.\n",
    "#### c) Hyper-parameters: number of components, kernel : {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘cosine’, ‘precomputed’}, alpha, eigen_solver : {‘auto’, ‘dense’, ‘arpack’, ‘randomized’}, tolerance and maximum number of iterations\n",
    "#### d) Defining: pca =KernelPCA() . Training: pca.fit_transform(X,y) . Testing: pca.get_covariance(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e685249",
   "metadata": {},
   "source": [
    "## Question 3 \n",
    "#### Dataset Link: https://www.kaggle.com/jmmvutu/summer-products-and-sales-in-ecommerce-wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e299541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"summer-products-with-rating-and-performance_2020-08.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da73f896",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1573 entries, 0 to 1572\n",
      "Data columns (total 43 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   title                         1573 non-null   object \n",
      " 1   title_orig                    1573 non-null   object \n",
      " 2   price                         1573 non-null   float64\n",
      " 3   retail_price                  1573 non-null   int64  \n",
      " 4   currency_buyer                1573 non-null   object \n",
      " 5   units_sold                    1573 non-null   int64  \n",
      " 6   uses_ad_boosts                1573 non-null   int64  \n",
      " 7   rating                        1573 non-null   float64\n",
      " 8   rating_count                  1573 non-null   int64  \n",
      " 9   rating_five_count             1528 non-null   float64\n",
      " 10  rating_four_count             1528 non-null   float64\n",
      " 11  rating_three_count            1528 non-null   float64\n",
      " 12  rating_two_count              1528 non-null   float64\n",
      " 13  rating_one_count              1528 non-null   float64\n",
      " 14  badges_count                  1573 non-null   int64  \n",
      " 15  badge_local_product           1573 non-null   int64  \n",
      " 16  badge_product_quality         1573 non-null   int64  \n",
      " 17  badge_fast_shipping           1573 non-null   int64  \n",
      " 18  tags                          1573 non-null   object \n",
      " 19  product_color                 1532 non-null   object \n",
      " 20  product_variation_size_id     1559 non-null   object \n",
      " 21  product_variation_inventory   1573 non-null   int64  \n",
      " 22  shipping_option_name          1573 non-null   object \n",
      " 23  shipping_option_price         1573 non-null   int64  \n",
      " 24  shipping_is_express           1573 non-null   int64  \n",
      " 25  countries_shipped_to          1573 non-null   int64  \n",
      " 26  inventory_total               1573 non-null   int64  \n",
      " 27  has_urgency_banner            473 non-null    float64\n",
      " 28  urgency_text                  473 non-null    object \n",
      " 29  origin_country                1556 non-null   object \n",
      " 30  merchant_title                1573 non-null   object \n",
      " 31  merchant_name                 1569 non-null   object \n",
      " 32  merchant_info_subtitle        1572 non-null   object \n",
      " 33  merchant_rating_count         1573 non-null   int64  \n",
      " 34  merchant_rating               1573 non-null   float64\n",
      " 35  merchant_id                   1573 non-null   object \n",
      " 36  merchant_has_profile_picture  1573 non-null   int64  \n",
      " 37  merchant_profile_picture      226 non-null    object \n",
      " 38  product_url                   1573 non-null   object \n",
      " 39  product_picture               1573 non-null   object \n",
      " 40  product_id                    1573 non-null   object \n",
      " 41  theme                         1573 non-null   object \n",
      " 42  crawl_month                   1573 non-null   object \n",
      "dtypes: float64(9), int64(15), object(19)\n",
      "memory usage: 528.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b111c78c",
   "metadata": {},
   "source": [
    "#### A) The variable we have to predict is a continouse variable as the product rating can be any number between 0 and 5. This is a supervised Machine learning problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53d603",
   "metadata": {},
   "source": [
    "#### B) I choose the Root Mean Squared Error as the measure of perfomance for my testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07cd047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9193f04e",
   "metadata": {},
   "source": [
    "#### C ) The variable which might be relevant for predicting the rating  are \n",
    "###### i) Price\n",
    "###### ii) Retail Price\n",
    "###### iii) Units Sold\n",
    "###### iv) Rating Count\n",
    "###### v) Product Variation Size ID\n",
    "###### vi) Product Variation Inventory\n",
    "###### vii) Shipping Option Price\n",
    "###### viii) Countries Shipped to\n",
    "###### ix) Merchant Rating Count\n",
    "###### x) Merchant Rating\n",
    "###### xi) Merchant has a profile picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1017c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.  ,  8.  ,  2.72,  3.92,  7.  , 12.  , 11.  ,  5.78,  5.79,\n",
       "        6.  ,  1.91,  2.  ,  5.  ,  9.  ,  5.71,  5.65,  1.74, 14.  ,\n",
       "        2.66,  5.8 , 13.  ,  3.69,  5.84,  1.  ,  5.87,  4.94,  5.83,\n",
       "        5.77,  5.9 ,  1.72,  1.86, 20.  ,  5.66,  5.81,  5.68, 17.  ,\n",
       "        5.86,  3.66,  1.68,  4.81, 18.  ,  3.78,  3.  ,  5.74,  3.67,\n",
       "       22.  , 19.  ,  4.83,  5.85, 15.  ,  5.69,  1.89,  4.  ,  3.85,\n",
       "        4.7 ,  4.84,  3.7 ,  1.77,  3.73,  1.75,  5.89,  2.71,  5.7 ,\n",
       "        5.72,  5.92, 24.  ,  1.8 ,  3.79,  1.65,  2.83,  1.85,  3.86,\n",
       "        2.76,  3.83,  3.93,  3.94,  4.67,  3.76,  4.73,  4.74,  5.95,\n",
       "        3.65,  2.81,  4.66,  2.8 ,  3.87,  5.75, 49.  , 23.  ,  5.73,\n",
       "        3.68,  4.86,  3.91,  3.88,  2.79,  1.76,  4.69,  4.65,  2.67,\n",
       "        1.71,  2.7 ,  3.81,  3.9 ,  4.68,  3.84,  4.9 , 25.  ,  2.65,\n",
       "        1.7 ,  3.74,  5.82,  3.71,  2.89,  5.67,  5.88,  4.93, 26.  ,\n",
       "        2.9 ,  1.88,  1.66,  4.88,  2.69,  1.67,  1.84,  3.72, 27.  ,\n",
       "        5.91])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df3[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e0c1023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 14,  22,  43,   8,   3,   9,   6,  11,  84,   5,  42,   2,  81,\n",
       "        10,  25,   7,  26,  32,  76,  17,  12,  13,  68,  40,  56,  50,\n",
       "        20,  60,  38,  67,  30,  33,  92,  51,  48,   4,  65,  15,  85,\n",
       "        59,  16, 115,  19,  89, 145,  36, 169,  21,  47,  34, 101,  41,\n",
       "        88, 118,  57, 104,  75,  27,  58, 134, 106, 108,  49, 152,  72,\n",
       "        46, 159,  28, 140, 168,  24,  18,  93,  37, 122,  86, 127,  70,\n",
       "       100, 126,  97, 250, 109,  55, 111,  54,  53,  69, 142,  31,  66,\n",
       "       102,  83,  23, 105, 110, 252, 135, 107,   1, 139,  29,  64,  87])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df3[\"retail_price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14870cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100       509\n",
       "1000      405\n",
       "5000      217\n",
       "10000     177\n",
       "20000     103\n",
       "50         76\n",
       "10         49\n",
       "50000      17\n",
       "100000      6\n",
       "8           4\n",
       "1           3\n",
       "7           2\n",
       "2           2\n",
       "3           2\n",
       "6           1\n",
       "Name: units_sold, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"units_sold\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586a3a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S                      641\n",
       "XS                     356\n",
       "M                      200\n",
       "XXS                    100\n",
       "L                       49\n",
       "                      ... \n",
       "6XL                      1\n",
       "AU plug Low quality      1\n",
       "XXXL                     1\n",
       "25-S                     1\n",
       "SIZE S                   1\n",
       "Name: product_variation_size_id, Length: 106, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"product_variation_size_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e40ecd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50    907\n",
       "1     152\n",
       "2      81\n",
       "5      74\n",
       "3      52\n",
       "10     40\n",
       "4      25\n",
       "9      22\n",
       "7      18\n",
       "6      18\n",
       "20     16\n",
       "15     13\n",
       "17     11\n",
       "18     10\n",
       "49      9\n",
       "13      8\n",
       "25      7\n",
       "19      7\n",
       "29      7\n",
       "46      6\n",
       "30      6\n",
       "8       6\n",
       "44      6\n",
       "11      6\n",
       "14      5\n",
       "12      5\n",
       "43      4\n",
       "36      4\n",
       "34      4\n",
       "35      4\n",
       "41      4\n",
       "48      4\n",
       "47      4\n",
       "27      3\n",
       "45      3\n",
       "39      2\n",
       "23      2\n",
       "31      2\n",
       "26      2\n",
       "28      2\n",
       "40      2\n",
       "38      2\n",
       "37      2\n",
       "21      2\n",
       "16      1\n",
       "22      1\n",
       "33      1\n",
       "24      1\n",
       "Name: product_variation_inventory, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"product_variation_inventory\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc80989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     619\n",
       "3     520\n",
       "1     308\n",
       "4      76\n",
       "5      32\n",
       "6      12\n",
       "7       5\n",
       "12      1\n",
       "Name: shipping_option_price, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"shipping_option_price\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e47e416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     171\n",
       "43     170\n",
       "40     106\n",
       "38      76\n",
       "36      64\n",
       "      ... \n",
       "124      1\n",
       "65       1\n",
       "71       1\n",
       "68       1\n",
       "72       1\n",
       "Name: countries_shipped_to, Length: 94, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"countries_shipped_to\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eddcb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32168    15\n",
       "12309    12\n",
       "80093     9\n",
       "42919     8\n",
       "88193     8\n",
       "         ..\n",
       "15006     1\n",
       "32923     1\n",
       "11965     1\n",
       "9661      1\n",
       "7023      1\n",
       "Name: merchant_rating_count, Length: 917, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"merchant_rating_count\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53c1f5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.884544    15\n",
       "4.045170    12\n",
       "4.006692     9\n",
       "4.105967     8\n",
       "4.080891     8\n",
       "            ..\n",
       "4.293241     1\n",
       "3.777778     1\n",
       "4.260596     1\n",
       "4.254335     1\n",
       "4.235939     1\n",
       "Name: merchant_rating, Length: 952, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"merchant_rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c4efa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1347\n",
       "1     226\n",
       "Name: merchant_has_profile_picture, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"merchant_has_profile_picture\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ff883",
   "metadata": {},
   "source": [
    "#### D) After seeing this variables, the following variables are usable:\n",
    "###### i) Price\n",
    "###### ii) Retail Price\n",
    "###### iii) Units Sold\n",
    "###### iv) Shipping Option Price\n",
    "###### v) Countries Shipped to\n",
    "###### vi) Merchant Rating Count\n",
    "###### vii) Merchant Rating\n",
    "###### viii) Merchant has a profile picture\n",
    "\n",
    "##### The Rating count is not usable as it can only be collected after a rating has been made and thus we don't have that information available prior to a rating. \n",
    "##### The Product Variation Size ID has also been dropped as there are many inconsistencies in the data as the data is not properly filled, thus that column will need some cleaning and thus I have avoided the data cleaning for now and am sticking to the other variables are there are plenty available to make an accurate prediction.\n",
    "##### The product variation inventory variable has also been excluded as that information is something the sellers have and does not directly influence the buyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e5d43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns3 = [\"price\",\"retail_price\",\"units_sold\",\"shipping_option_price\",\"countries_shipped_to\",\"merchant_rating_count\"\n",
    "             , \"merchant_rating\",\"merchant_has_profile_picture\",\"rating\"]\n",
    "variables3 = [\"price\",\"retail_price\",\"units_sold\",\"shipping_option_price\",\"countries_shipped_to\",\"merchant_rating_count\"\n",
    "             , \"merchant_rating\",\"merchant_has_profile_picture\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a87fee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[columns3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec05fcfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1573 entries, 0 to 1572\n",
      "Data columns (total 9 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   price                         1573 non-null   float64\n",
      " 1   retail_price                  1573 non-null   int64  \n",
      " 2   units_sold                    1573 non-null   int64  \n",
      " 3   shipping_option_price         1573 non-null   int64  \n",
      " 4   countries_shipped_to          1573 non-null   int64  \n",
      " 5   merchant_rating_count         1573 non-null   int64  \n",
      " 6   merchant_rating               1573 non-null   float64\n",
      " 7   merchant_has_profile_picture  1573 non-null   int64  \n",
      " 8   rating                        1573 non-null   float64\n",
      "dtypes: float64(3), int64(6)\n",
      "memory usage: 110.7 KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db158533",
   "metadata": {},
   "source": [
    "#### E) There are no missing variables and and there is no categorical data present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733642fe",
   "metadata": {},
   "source": [
    "#### F) There are 8 variables so we do not require PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451adcc3",
   "metadata": {},
   "source": [
    "#### G) I will be using 3 ML frameworks , namely LASSO, SVM for regression and Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "374a010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train3 = df3[variables3].iloc[:(len(df3)*70)//100]\n",
    "valid3 = df3[variables3].iloc[(len(df3)*70)//100:(len(df3)*85)//100]\n",
    "test3 = df3[variables3].iloc[(len(df3)*85)//100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e57090",
   "metadata": {},
   "source": [
    "#### I) The Hyperparameters used are as follows.\n",
    "#### Support Vector machine for regression:\n",
    "##### i) Epsilon\n",
    "##### ii) Tolerance\n",
    "##### iii) Regularization Parameter\n",
    "#### Lasso:\n",
    "##### i) Alpha\n",
    "##### ii) Normalize\n",
    "##### iii) Tolerance\n",
    "#### Ridge:\n",
    "##### i) Alpha\n",
    "##### ii) Normalize\n",
    "##### iii) Tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59f713",
   "metadata": {},
   "source": [
    "#### Importing ML frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dabda685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39e9e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = GridSearchCV(estimator=Lasso(),param_grid = {'alpha':[-100,100],'normalize':[True,False],'tol':[1e-5,1e-3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15ec593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lasso())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Lasso(),\n",
       "             param_grid={'alpha': [-100, 100], 'normalize': [True, False],\n",
       "                         'tol': [1e-05, 0.001]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(train3,df3[\"rating\"].iloc[:(len(df3)*70)//100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a1d30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_val = lasso.predict(valid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bbe4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = GridSearchCV(estimator=SVR(),param_grid = {\"C\":[0,2],\"epsilon\":[-0.15,0.15],'tol':[0.05,0.15]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4bac884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: epsilon < 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      " -0.01201125 -0.01047548]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVR(),\n",
       "             param_grid={'C': [0, 2], 'epsilon': [-0.15, 0.15],\n",
       "                         'tol': [0.05, 0.15]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.fit(train3,df3[\"rating\"].iloc[:(len(df3)*70)//100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b76e5029",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_val = svr.predict(valid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0822399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = GridSearchCV(estimator=Ridge(),param_grid = {'alpha':[-100,100],'normalize':[True,False],'tol':[1e-5,1e-3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f54ddd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * n_samples. \n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Ridge(),\n",
       "             param_grid={'alpha': [-100, 100], 'normalize': [True, False],\n",
       "                         'tol': [1e-05, 0.001]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(train3,df3[\"rating\"].iloc[:(len(df3)*70)//100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "027b855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_val = ridge.predict(valid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3deaac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_err = mean_squared_error(y_true=df3[\"rating\"].iloc[(len(df3)*70)//100:(len(df3)*85)//100],y_pred=lasso_val)\n",
    "svr_err = mean_squared_error(y_true=df3[\"rating\"].iloc[(len(df3)*70)//100:(len(df3)*85)//100],y_pred=svr_val)\n",
    "ridge_err = mean_squared_error(y_true=df3[\"rating\"].iloc[(len(df3)*70)//100:(len(df3)*85)//100],y_pred=ridge_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32b91e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Validation Error : 0.2477584363143904\n",
      "SVM Validation Error : 0.24985287532435316\n",
      "Ridge Validation Error : 0.24700392194835602\n"
     ]
    }
   ],
   "source": [
    "print(f\"Lasso Validation Error : {lasso_err}\")\n",
    "print(f\"SVM Validation Error : {svr_err}\")\n",
    "print(f\"Ridge Validation Error : {ridge_err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518393d9",
   "metadata": {},
   "source": [
    "#### K) Since the root mean squared error for the Ridge Regression model is least, we select the Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fce0529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Root Mean Squared error : 0.2674133595497318\n"
     ]
    }
   ],
   "source": [
    "ridge_test = ridge.predict(test3)\n",
    "ridge_terror = mean_squared_error(y_true=df3[\"rating\"].iloc[(len(df3)*85)//100:],y_pred=ridge_test)\n",
    "print(f\"Test Root Mean Squared error : {ridge_terror}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109b349",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Dataset Link: https://www.kaggle.com/kyr7plus/emg-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e8044e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_1 = pd.read_csv(\"Q4/0.csv\",header=None)\n",
    "df4_2 = pd.read_csv(\"Q4/1.csv\",header=None)\n",
    "df4_3 = pd.read_csv(\"Q4/2.csv\",header=None)\n",
    "df4_4 = pd.read_csv(\"Q4/3.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2480284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df4_1,df4_2,df4_3,df4_4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c9c3c45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-109.0</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-59.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-47.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11673</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11674</th>\n",
       "      <td>-13.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11675</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-90.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11677</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11678 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1    2    3     4     5      6     7     8    9   ...    55  \\\n",
       "0      26.0  4.0  5.0  8.0  -1.0 -13.0 -109.0 -66.0  -9.0  2.0  ... -28.0   \n",
       "1     -47.0 -6.0 -5.0 -7.0  13.0  -1.0   35.0 -10.0  10.0 -4.0  ... -25.0   \n",
       "2     -19.0 -8.0 -8.0 -8.0 -21.0  -6.0  -79.0  12.0   0.0  5.0  ... -83.0   \n",
       "3       2.0  3.0  0.0  2.0   0.0  22.0  106.0 -14.0 -16.0 -2.0  ... -38.0   \n",
       "4       6.0  0.0  0.0 -2.0 -14.0  10.0  -51.0   5.0   7.0  0.0  ...  38.0   \n",
       "...     ...  ...  ...  ...   ...   ...    ...   ...   ...  ...  ...   ...   \n",
       "11673  -3.0 -1.0 -1.0 -1.0 -28.0  20.0    5.0   0.0  -5.0  0.0  ...  -3.0   \n",
       "11674 -13.0 -5.0 -4.0 -3.0  -4.0 -24.0  -10.0  -8.0  20.0  9.0  ...   6.0   \n",
       "11675  -1.0 -3.0 -1.0  1.0  30.0  38.0   -1.0  36.0 -10.0  1.0  ...  14.0   \n",
       "11676   1.0  4.0  4.0  5.0   9.0 -10.0    4.0   1.0  -2.0 -1.0  ... -16.0   \n",
       "11677  -2.0  4.0  2.0 -4.0  12.0   3.0   -2.0   9.0  -8.0 -2.0  ...   2.0   \n",
       "\n",
       "         56   57   58    59    60    61     62    63  64  \n",
       "0      61.0  4.0  8.0   5.0   4.0  -7.0  -59.0  16.0   0  \n",
       "1      47.0  6.0  6.0   5.0  13.0  21.0  111.0  15.0   0  \n",
       "2       7.0  7.0  1.0  -8.0   7.0  21.0  114.0  48.0   0  \n",
       "3     -11.0  4.0  7.0  11.0  33.0  39.0  119.0  43.0   0  \n",
       "4     -35.0 -8.0  2.0   6.0 -13.0 -24.0 -112.0 -69.0   0  \n",
       "...     ...  ...  ...   ...   ...   ...    ...   ...  ..  \n",
       "11673   1.0  4.0  3.0   4.0 -51.0 -49.0    5.0  -9.0   3  \n",
       "11674  -3.0 -3.0 -3.0  -5.0  -4.0 -45.0  -12.0 -15.0   3  \n",
       "11675  -8.0 -4.0 -4.0  -4.0 -21.0 -29.0   -5.0   0.0   3  \n",
       "11676  -3.0  0.0 -3.0  -5.0 -36.0 -90.0    3.0   5.0   3  \n",
       "11677   1.0  0.0 -1.0  -2.0 -30.0  64.0   11.0   5.0   3  \n",
       "\n",
       "[11678 rows x 65 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45bff312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = df4.rename(columns={64:\"Target\"})\n",
    "pd.unique(df4[\"Target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddfeeb",
   "metadata": {},
   "source": [
    "Shuffling Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ec1a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.sample(frac = 1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb32e7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11673</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11674</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11675</th>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11676</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11677</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11678 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9  ...    55  \\\n",
       "0      20.0   8.0   9.0   2.0  15.0 -16.0   2.0   4.0 -27.0 -55.0  ...  -5.0   \n",
       "1      -2.0 -12.0  -8.0 -10.0   7.0  -3.0  -4.0  20.0   3.0  14.0  ...  -2.0   \n",
       "2       9.0  13.0  -5.0  -7.0 -25.0 -65.0  18.0  -7.0  40.0   7.0  ... -13.0   \n",
       "3       0.0   1.0  -3.0  -3.0  26.0  20.0   2.0   3.0   3.0  -2.0  ...  -3.0   \n",
       "4      10.0 -19.0 -16.0 -11.0   4.0  17.0  -2.0 -18.0  -5.0   8.0  ...  12.0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "11673  -7.0  17.0   1.0  -3.0 -27.0 -10.0 -19.0  -7.0  26.0   5.0  ... -10.0   \n",
       "11674  -7.0  -2.0   0.0   5.0  13.0 -10.0  -2.0   3.0 -10.0  -3.0  ...  -5.0   \n",
       "11675  26.0  16.0   2.0  -2.0 -21.0  16.0   0.0  -3.0 -40.0 -20.0  ...  -4.0   \n",
       "11676  -4.0   1.0  -2.0   1.0  27.0  72.0   4.0  -7.0   3.0   0.0  ... -10.0   \n",
       "11677  -9.0   6.0   0.0   7.0  20.0  26.0  -3.0   1.0  57.0  63.0  ... -10.0   \n",
       "\n",
       "         56    57    58   59    60    61    62    63  Target  \n",
       "0      -2.0   3.0   6.0  8.0  23.0  37.0 -11.0  -3.0       2  \n",
       "1       3.0  -3.0  -4.0 -8.0  12.0  11.0   1.0   3.0       2  \n",
       "2       3.0  12.0  10.0 -2.0  26.0  38.0   9.0  14.0       2  \n",
       "3      -1.0   4.0   6.0  7.0 -36.0 -15.0   0.0  12.0       1  \n",
       "4      10.0  16.0   4.0 -1.0   4.0  28.0  -2.0 -22.0       2  \n",
       "...     ...   ...   ...  ...   ...   ...   ...   ...     ...  \n",
       "11673  28.0 -20.0 -12.0 -4.0   0.0  33.0   9.0   6.0       2  \n",
       "11674 -16.0  -5.0  -4.0 -8.0 -17.0  -7.0  -2.0  -5.0       1  \n",
       "11675  -5.0  -2.0  -2.0 -1.0   1.0  10.0  -4.0   6.0       1  \n",
       "11676   5.0  -4.0  -3.0 -5.0   0.0 -40.0 -13.0   6.0       3  \n",
       "11677  -2.0  -5.0  18.0  2.0   4.0 -16.0   0.0   3.0       2  \n",
       "\n",
       "[11678 rows x 65 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da5182",
   "metadata": {},
   "source": [
    "#### A) Since the target variable only takes discrete values, this is a classification problem. Since the labels are present, this is a supervised machine learning problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cec503",
   "metadata": {},
   "source": [
    "#### B) I will be using the F-1 Score method since this problem is a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbe357a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159ff40",
   "metadata": {},
   "source": [
    "#### C)  All variables are usable as each variable in unique as they correspond to either a different sensor, a different point in time or both together. \n",
    "#### D) Since the variables are present in multiples of 8 because it contains 8 different sensors and the data was collected for 8 different points in time with a frequency of 200Hz, we can use all the variables present or subsets of the different times of collection. Because we have a large data set we will use all 64 input columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b09fb0",
   "metadata": {},
   "source": [
    "#### E) As there are no categorical variables and no missing data, we can skip this point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858ca05",
   "metadata": {},
   "source": [
    "#### F) Since the next question asks us to explicitly perform PCA and analyse, I will use all variables without reducing dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb1426",
   "metadata": {},
   "source": [
    "#### G) Since the number of samples is greater than 50 and less than 100k, we use Linear Support Vector Machines for classification according to the guidlines mentioned in https://scikit-learn.org/stable/tutorial/machine_learning_map/ .  In case SVM does not work for this, we use Random Forest Classifier as a second ML framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c1c88",
   "metadata": {},
   "source": [
    "#### H) Dividing data into training, validation and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46fe7380",
   "metadata": {},
   "outputs": [],
   "source": [
    "train4 = df4[[i for i in range(64)]].iloc[:(len(df4)*70)//100]\n",
    "valid4 = df4[[i for i in range(64)]].iloc[(len(df4)*70)//100:(len(df4)*85)//100]\n",
    "test4 = df4[[i for i in range(64)]].iloc[(len(df4)*85)//100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a91a8c",
   "metadata": {},
   "source": [
    "#### I) The Hyperparameters used are as follows.\n",
    "####  Support Vector machine for classification:\n",
    "##### i) Gamma\n",
    "##### ii) Tolerance\n",
    "##### iii) Regularization Parameter\n",
    "#### Random Forest Classifier:\n",
    "##### i) The number of trees in the forest.\n",
    "##### ii) The minimum number of samples required to split an internal node\n",
    "##### iii) The number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db02f3",
   "metadata": {},
   "source": [
    "#### Importing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c18196d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7201e7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 255, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 315, in _dense_fit\n",
      "    ) = libsvm.fit(\n",
      "  File \"sklearn/svm/_libsvm.pyx\", line 192, in sklearn.svm._libsvm.fit\n",
      "ValueError: C <= 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.87704947 0.87704947\n",
      " 0.25116227 0.25116227]\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0, 2], 'gamma': ['scale', 'auto'],\n",
       "                         'tol': [1e-05, 0.001]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = GridSearchCV(estimator=SVC(),param_grid = {'gamma':['scale','auto'],'tol':[1e-5,1e-3],'C':[0,2]})\n",
    "y_train = df4[[\"Target\"]].iloc[:(len(df4)*70)//100]\n",
    "svc.fit(train4, y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1a97d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_val = svc.predict(valid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07db9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = GridSearchCV(RandomForestClassifier(),{'n_estimators':[50,150],'min_samples_split':[2,4],'max_features' :['sqrt', 'log2']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "923e24f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:681: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/model_selection/_search.py:926: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 4],\n",
       "                         'n_estimators': [50, 150]})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train4, df4[[\"Target\"]].iloc[:(len(df4)*70)//100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5218a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_val = rf.predict(valid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1343aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_f1 = sklearn.metrics.f1_score(y_true = df4[[\"Target\"]].iloc[(len(df4)*70)//100:(len(df4)*85)//100], y_pred = svc_val,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e57e45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_f1 = sklearn.metrics.f1_score(y_true = df4[[\"Target\"]].iloc[(len(df4)*70)//100:(len(df4)*85)//100], y_pred = rf_val,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb1eb312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC F1 Score for Validation Set: 0.8883341888687134\n",
      "Random Forest F1 Score for Validation Set: 0.9219950351100868\n"
     ]
    }
   ],
   "source": [
    "print(f\"SVC F1 Score for Validation Set: {svc_f1}\")\n",
    "print(f\"Random Forest F1 Score for Validation Set: {rf_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3559d",
   "metadata": {},
   "source": [
    "#### Thus we can see that the F1 Score of Random Forest is much better , thus we use Random Forest for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cde19677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest F1 Score for Test Set: 0.9204811756554807\n"
     ]
    }
   ],
   "source": [
    "rf_test = rf.predict(test4)\n",
    "rf_testf1 = sklearn.metrics.f1_score(y_true = df4[[\"Target\"]].iloc[(len(df4)*85)//100:], y_pred = rf_test,average='macro')\n",
    "print(f\"Random Forest F1 Score for Test Set: {rf_testf1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad986c",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Dataset Link: https://www.kaggle.com/kyr7plus/emg-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cb0c81fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7326c223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11673</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11674</th>\n",
       "      <td>-7.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11675</th>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11676</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11677</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11678 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1     2     3     4     5     6     7     8     9  ...    55  \\\n",
       "0      20.0   8.0   9.0   2.0  15.0 -16.0   2.0   4.0 -27.0 -55.0  ...  -5.0   \n",
       "1      -2.0 -12.0  -8.0 -10.0   7.0  -3.0  -4.0  20.0   3.0  14.0  ...  -2.0   \n",
       "2       9.0  13.0  -5.0  -7.0 -25.0 -65.0  18.0  -7.0  40.0   7.0  ... -13.0   \n",
       "3       0.0   1.0  -3.0  -3.0  26.0  20.0   2.0   3.0   3.0  -2.0  ...  -3.0   \n",
       "4      10.0 -19.0 -16.0 -11.0   4.0  17.0  -2.0 -18.0  -5.0   8.0  ...  12.0   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "11673  -7.0  17.0   1.0  -3.0 -27.0 -10.0 -19.0  -7.0  26.0   5.0  ... -10.0   \n",
       "11674  -7.0  -2.0   0.0   5.0  13.0 -10.0  -2.0   3.0 -10.0  -3.0  ...  -5.0   \n",
       "11675  26.0  16.0   2.0  -2.0 -21.0  16.0   0.0  -3.0 -40.0 -20.0  ...  -4.0   \n",
       "11676  -4.0   1.0  -2.0   1.0  27.0  72.0   4.0  -7.0   3.0   0.0  ... -10.0   \n",
       "11677  -9.0   6.0   0.0   7.0  20.0  26.0  -3.0   1.0  57.0  63.0  ... -10.0   \n",
       "\n",
       "         56    57    58   59    60    61    62    63  Target  \n",
       "0      -2.0   3.0   6.0  8.0  23.0  37.0 -11.0  -3.0       2  \n",
       "1       3.0  -3.0  -4.0 -8.0  12.0  11.0   1.0   3.0       2  \n",
       "2       3.0  12.0  10.0 -2.0  26.0  38.0   9.0  14.0       2  \n",
       "3      -1.0   4.0   6.0  7.0 -36.0 -15.0   0.0  12.0       1  \n",
       "4      10.0  16.0   4.0 -1.0   4.0  28.0  -2.0 -22.0       2  \n",
       "...     ...   ...   ...  ...   ...   ...   ...   ...     ...  \n",
       "11673  28.0 -20.0 -12.0 -4.0   0.0  33.0   9.0   6.0       2  \n",
       "11674 -16.0  -5.0  -4.0 -8.0 -17.0  -7.0  -2.0  -5.0       1  \n",
       "11675  -5.0  -2.0  -2.0 -1.0   1.0  10.0  -4.0   6.0       1  \n",
       "11676   5.0  -4.0  -3.0 -5.0   0.0 -40.0 -13.0   6.0       3  \n",
       "11677  -2.0  -5.0  18.0  2.0   4.0 -16.0   0.0   3.0       2  \n",
       "\n",
       "[11678 rows x 65 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "422f5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed758aae",
   "metadata": {},
   "source": [
    "#### Caluculating the Standard Deviation of the L2 norm of the input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cdf08730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Standard Deviation of the L2 Norm of the 64 Variable Input is : 50.94542928609859\n",
      "1% of the Standard Deviation of the L2 Norm of the 64 Variable Input is : 0.5094542928609859\n"
     ]
    }
   ],
   "source": [
    "X5 = df5[[i for i in range(64)]]\n",
    "l2_norm = np.sqrt(np.square(X5).sum(axis=1))\n",
    "std5 = np.std(l2_norm)\n",
    "print(f\"The Standard Deviation of the L2 Norm of the 64 Variable Input is : {std5}\")\n",
    "print(f\"1% of the Standard Deviation of the L2 Norm of the 64 Variable Input is : {0.01*std5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a395ff",
   "metadata": {},
   "source": [
    "#### Calculating RMSE for various dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77b930ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 15.369997367575204 with 1 components\n",
      "RMSE: 14.8850031092706 with 2 components\n",
      "RMSE: 14.439300902593226 with 3 components\n",
      "RMSE: 14.001725996289474 with 4 components\n",
      "RMSE: 13.557130401491488 with 5 components\n",
      "RMSE: 13.135572206581934 with 6 components\n",
      "RMSE: 12.713620319035785 with 7 components\n",
      "RMSE: 12.265176941907496 with 8 components\n",
      "RMSE: 11.862604991018182 with 9 components\n",
      "RMSE: 11.537820814364755 with 10 components\n",
      "RMSE: 11.209822804110264 with 11 components\n",
      "RMSE: 10.860400031983762 with 12 components\n",
      "RMSE: 10.50270400140454 with 13 components\n",
      "RMSE: 10.180264157869297 with 14 components\n",
      "RMSE: 9.822250865835617 with 15 components\n",
      "RMSE: 9.515835009456426 with 16 components\n",
      "RMSE: 9.25961562839522 with 17 components\n",
      "RMSE: 9.002782383053297 with 18 components\n",
      "RMSE: 8.72924664094951 with 19 components\n",
      "RMSE: 8.47913886942121 with 20 components\n",
      "RMSE: 8.21841385958793 with 21 components\n",
      "RMSE: 7.951596802214354 with 22 components\n",
      "RMSE: 7.643106823396131 with 23 components\n",
      "RMSE: 7.431361103674205 with 24 components\n",
      "RMSE: 7.220869575904908 with 25 components\n",
      "RMSE: 7.010290968041065 with 26 components\n",
      "RMSE: 6.798748049155759 with 27 components\n",
      "RMSE: 6.52328903030015 with 28 components\n",
      "RMSE: 6.3171141016091585 with 29 components\n",
      "RMSE: 6.093420678841043 with 30 components\n",
      "RMSE: 5.9252093373778685 with 31 components\n",
      "RMSE: 5.688924094714954 with 32 components\n",
      "RMSE: 5.451000754766129 with 33 components\n",
      "RMSE: 5.210368963200125 with 34 components\n",
      "RMSE: 4.94575293402308 with 35 components\n",
      "RMSE: 4.577029789680738 with 36 components\n",
      "RMSE: 4.379811620696711 with 37 components\n",
      "RMSE: 4.193966214223168 with 38 components\n",
      "RMSE: 3.974430601638025 with 39 components\n",
      "RMSE: 3.7554812779790088 with 40 components\n",
      "RMSE: 3.5257241168185667 with 41 components\n",
      "RMSE: 3.403718006122733 with 42 components\n",
      "RMSE: 3.2826415620100793 with 43 components\n",
      "RMSE: 3.0443008924138866 with 44 components\n",
      "RMSE: 2.8432678340034814 with 45 components\n",
      "RMSE: 2.668971872556232 with 46 components\n",
      "RMSE: 2.431449096021964 with 47 components\n",
      "RMSE: 2.2913293284179566 with 48 components\n",
      "RMSE: 2.1050436278715168 with 49 components\n",
      "RMSE: 1.9540956613835028 with 50 components\n",
      "RMSE: 1.8110822856441038 with 51 components\n",
      "RMSE: 1.6015926409161239 with 52 components\n",
      "RMSE: 1.2815411009905135 with 53 components\n",
      "RMSE: 0.8961308991700125 with 54 components\n",
      "RMSE: 0.7610407625186912 with 55 components\n",
      "RMSE: 0.6866123283583537 with 56 components\n",
      "RMSE: 0.6140575903296118 with 57 components\n",
      "RMSE: 0.5428784217731701 with 58 components\n",
      "RMSE: 0.4791962756469548 with 59 components\n",
      "RMSE: 0.40556515388764974 with 60 components\n",
      "RMSE: 0.32770811970646485 with 61 components\n",
      "RMSE: 0.21755222030653848 with 62 components\n",
      "RMSE: 0.12636908121362714 with 63 components\n",
      "RMSE: 3.785092067078616e-14 with 64 components\n"
     ]
    }
   ],
   "source": [
    "rmse_dict = {}\n",
    "components = [i+1 for i in range(64)]\n",
    "for n in components:\n",
    "    pca = PCA(n_components=n)\n",
    "    recon = pca.inverse_transform(pca.fit_transform(df5[[i for i in range(64)]]))\n",
    "    rmse = mean_squared_error(df5[[i for i in range(64)]], recon,squared=False)\n",
    "    rmse_dict[n] = rmse\n",
    "    print(f\"RMSE: {rmse} with {n} components\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7492c95f",
   "metadata": {},
   "source": [
    "#### Thus we see that to get a RMSE Reconstruction error less than 1% of the standard deviation of the L2 norm of the 64 variable input, we need at least 59 dimensions or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5460ac26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIwAAAJcCAYAAACbuD+6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABcd0lEQVR4nO3dd3iddf3/8ec7SQuUIQJlUyBQkjYMwYAgyFZACENkKQriFxzgFwEVFRVQRFGG4kKUoQLyZUtANrJBLZvQhJZAGWVvKFCafH5/fE5+SUpTus65T5Ln47py3ee+75OcV8qBpC8+I1JKSJIkSZIkST1qig4gSZIkSZKk6mJhJEmSJEmSpH4sjCRJkiRJktSPhZEkSZIkSZL6sTCSJEmSJElSPxZGkiRJkiRJ6sfCSJIkSZIkSf1YGEmSJH2AiHg8It6OiDcj4rmIODsiFivd2y4ibomINyLihYi4OSJ2nunzt4yIFBFHFvMdSJIkzR0LI0mSpDnTklJaDNgAaAZ+EBGfBS4E/gqsDCwH/Ahomelz9wNeBr5YubiSJEnzzsJIkiRpLqSUngauAtYBTgZ+klL6c0rptZRSd0rp5pTSgT3Pj4hFgc8CBwNjI6K5kOCSJElzwcJIkiRpLkTEKsCngWnAKsBFH/ApnwHeJI9EuoY82kiSJKmqWRhJkiTNmcsi4lXgNuBm4Fel6898wOftB/xfSqkLOA/YOyJGlCukJEnSgmBhJEmSNGd2TSktmVJaNaX0deCl0vUVBvqE0mikrYBzS5f+ASwM7FjWpJIkSfPJwkiSJGnedABPArvP5jlfIP++1RoRzwKd5MLIaWmSJKmqWRhJkiTNg5RSAg4HfhgRX4qIJSKiJiI2i4jTS0/bDzgW+Eifj92BT0fE0pVPLUmSNGcsjCRJkuZRSukiYC/gAGAq8BxwHPCPiNgYWBX4XUrp2T4flwOTgX2Kyi1JkvRBIv/PMUmSJEmSJClzhJEkSZIkSZL6sTCSJEmSJElSPxZGkiRJkiRJ6sfCSJIkSZIkSf3UFR1gTiyzzDJptdVWKzqGJEmSJEnSkHH33Xe/mFIaPat7g6IwWm211ZgwYULRMSRJkiRJkoaMiJgy0L2yTUmLiDMj4vmIeGim69+IiPaIaIuIX5Tr9SVJkiRJkjRvyrmG0dnA9n0vRMRWwC7AeimlJuDEMr6+JEmSJEmS5kHZCqOU0i3AyzNd/hrw85TSu6XnPF+u15ckSZIkSdK8qfQuaWsBn4iIf0fEzRGx4UBPjIiDImJCREx44YUXKhhRkiRJkiRpeKt0YVQHLAVsDHwbuCAiYlZPTCmdnlJqTik1jx49ywW7JUmSJEmSVAaVLoyeAi5J2X+AbmCZCmeQJEmSJEnSbFS6MLoM2AogItYCRgIvVjiDJEmSJEmSZqOuXF84Iv4ObAksExFPAUcDZwJnRsRDwHRgv5RSKlcGSZIkSZIkzb2yFUYppX0GuLVvuV5TkiRJkiRJ86/SU9IkSZIkSZJU5SyMJEmSJEmS1I+FkSRJkiRJkvqxMJIkSZIkSVI/FkaSJEmSJEnqx8JIkiRJkiRJ/VgYSZIkSZIkqR8LI0mSJEmSJPVjYSRJkiRJkqR+LIwkSZIkSZLUj4WRJEmSJEmS+rEwkiRJkiRJUj8WRhXS2QlNTVBXl4+dnUUnkiRJkiRJmjULowppaYH2dujqyseWlqITSZIkSZIkzZqFUYV0dEB3d37c3Z3PJUmSJEmSqpGFUYU0NEBNnz/tZZctLoskSZIkSdLsWBhVSGsrNDZCbS0sthg88wz86ldFp5IkSZIkSXo/C6MKqa+HtjaYMQNeegl23x3++Ed4++2ik0mSJEmSJPVXV3SA4WjkSDj/fHjlFVhkkbwQdk0NRBSdTJIkSZIkyRFGhamrg9Gj84ijffaB738fUio6lSRJkiRJkoVR4WpqYOml4ec/h8MPtzSSJEmSJEnFc0pawWpq4Pe/h4UWyotgv/MO/O53/XdUkyRJkiRJqiQLoyoQAaecktcz+vnPYcQIOPXUolNJkiRJkqThysKoSkTA8cfD4ovDFlsUnUaSJEmSJA1nTnyqIhF58etNN83n//gHTJ9ebCZJkiRJkjT8WBhVqQcegF13hd13z+saSZIkSZIkVYqFUZVad134wx/giitgl11g2rSiE0mSJEmSpOHCwqiKffWrcOaZcN11sOOO8OabRSeSJEmSJEnDgYVRlfvSl+Ccc+CWW2DcOKirg6Ym6OwsOpkkSZIkSRqqLIwGgc99DurrYepU6OqC9nZoaSk6lSRJkiRJGqosjAaJxx6D7u78uLsbOjqKzSNJkiRJkoYuC6NBoqEBavr800oJbr+9uDySJEmSJGnosjAaJFpbobERamthzTVhzBjYdlu47LKik0mSJEmSpKHGwmiQqK+HtjaYMQMmTYL//AfWWw923x1uvbXodJIkSZIkaSipKzqA5s3o0XDjjfC738HHP150GkmSJEmSNJQ4wmgQGzUKvv3tPE3tySfhiCNg+vSiU0mSJEmSpMHOwmiIuOoqOPlkaGmBN94oOo0kSZIkSRrMLIyGiIMOgjPOgBtugC22gGefLTqRJEmSJEkarCyMhpADDsi7qXV0wCabwKOPFp1IkiRJkiQNRhZGQ8wOO8BNN8Gaa8IyyxSdRpIkSZIkDUYWRkPQhhvCddfBhz4Eb7+dd1OTJEmSJEmaUxZGQ9xPfgKf/CScdlrRSSRJkiRJ0mBhYTTEHXVUnqb2ta/B6NFQVwdNTdDZWXQySZIkSZJUrSyMhrhFF4XLLoMll4QXX4SuLmhvh5aWopNJkiRJkqRqZWE0DNTVwRtv9J53d+ed1CRJkiRJkmbFwmiYaGiAmtI/7ZqafP7ii8VmkiRJkiRJ1cnCaJhobYXGRqitzccddoD11oP77is6mSRJkiRJqjYWRsNEfT20tcGMGfm43355pNEnPgHXXFN0OkmSJEmSVE0sjIapddaBu+6CNdaAHXeEM84oOpEkSZIkSaoWFkbD2Eorwa23wrbbwle/Co8+WnQiSZIkSZJUDeqKDqBiLb54Xt+oZ7QRQEoQUWwuSZIkSZJUHEcYiREj8lpGABdfDJ/8JLz6aqGRJEmSJElSgSyM1M8778Att8Bmm8ETTxSdRpIkSZIkFcHCSP18/vNw9dXw1FOw8cZw771FJ5IkSZIkSZVmYaT32XpruP12qKvLU9Uef7zoRJIkSZIkqZLKVhhFxJkR8XxEPDSLe0dERIqIZcr1+po/TU15Ieyf/ARWW63oNJIkSZIkqZLKOcLobGD7mS9GxCrApwBXyKlyK64Ihx2WH//zn7DssnnUUVMTdHYWm02SJEmSJJVP2QqjlNItwMuzuHUK8B0gleu1teDttx+88AJ0dUF7O7S0FJ1IkiRJkiSVS0XXMIqIXYCnU0r3z8FzD4qICREx4YUXXqhAOs3OK6/0Pu7uho6O4rJIkiRJkqTyqlhhFBGjgO8DP5qT56eUTk8pNaeUmkePHl3ecPpADQ1Q0+fdUlcHzz9fXB5JkiRJklQ+lRxhtAawOnB/RDwOrAzcExHLVzCD5lFrKzQ2Qm0trLoqbLEFLLlk0akkSZIkSVI51FXqhVJKDwLL9pyXSqPmlNKLlcqgeVdfD21t77/+4ovwyCPw8Y9XPpMkSZIkSSqPso0wioi/A3cCDRHxVER8uVyvpeIcfjhsvTVcdFHRSSRJkiRJ0oJSzl3S9kkprZBSGpFSWjmldMZM91dzdNHgd8op8NGPwp57wq9/XXQaSZIkSZK0IFR0lzQNPUsvDddfD7vuCt/8JnzrW3kXNUmSJEmSNHhZGGm+LbIIXHghHHIIXHYZvPpq0YkkSZIkSdL8qNii1xraamvh1FPhlVdgqaXgvfdg2jT40IeKTiZJkiRJkuaWI4y0wETksgjg4INhs83gqaeKzSRJkiRJkuaehZHKYq+9YMoU2GQTeOihotNIkiRJkqS5YWGksthmG7j1VujqyiONbrqp6ESSJEmSJGlOWRipbNZbD+66C1ZcEXbbDcaNg7o6aGqCzs6i00mSJEmSpIFYGKmsxoyB22+HJZeERx7JI47a26GlpehkkiRJkiRpIBZGKrsPfxiefBK6u/N5dzd0dBSbSZIkSZIkDczCSBXR0AA1fd5tCy0Er7xSXB5JkiRJkjQwCyNVRGsrNDZCbW1e0+i992DjjWHSpKKTSZIkSZKkmVkYqSLq66GtDWbMgKefhhtvhJdfhk02caSRJEmSJEnVpq7oABqeNtsM/vMfuPnmvMaRJEmSJEmqHo4wUmFWXx323z8/vu46+Pa38y5qkiRJkiSpWBZGqgo33QQnngi77gpvvFF0GkmSJEmShjcLI1WFn/4Ufvc7uOoq2HRTmDKl6ESSJEmSJA1fFkaqGl//ei6MnngCNtoInnyy6ESSJEmSJA1PLnqtqvLJT8Kdd8Jf/worr1x0GkmSJEmShidHGKnqjBsHP/sZRMCkSflxSkWnkiRJkiRp+LAwUlX729/g+9+HffaBt98uOo0kSZIkScODhZGq2rHHwgknwP/9Hyy1FNTVQVMTdHYWnUySJEmSpKHLwkhVLQK+8x1YZRV45x3o6oL2dmhpKTqZJEmSJElDl4WRBoWpU3sfd3dDR0dxWSRJkiRJGuosjDQoNDRATendWlMDY8fCmWe6GLYkSZIkSeVgYaRBobUVGhuhtjYfd94ZvvxlOOggmD696HSSJEmSJA0tdUUHkOZEfT20tfWed3fDyJFw3HHw6KNw0UV5UWxJkiRJkjT/HGGkQammBn7yE/jrX+H222HjjWHSpKJTSZIkSZI0NFgYaVD7whfgxhth1ChYZJGi00iSJEmSNDRYGGnQ23RTuOceWHll6OqCq64qOpEkSZIkSYObhZGGhJ4d1M46Cz79aTjiiFweSZIkSZKkueei1xpS9t8fHngATj4ZHnkEzjsPFl+86FSSJEmSJA0ujjDSkFJXB6eeCr/7XZ6atummMGVK0akkSZIkSRpcLIw0JH396/DPf8Lzz8MzzxSdRpIkSZKkwcXCSEPWpz4FnZ2w8cb5uMYaeQRSU1M+lyRJkiRJs2ZhpCFt1Kh83HLLXBJ1dUF7O7S0FBpLkiRJkqSqZmGkYWHq1N7H3d3Q0VFcFkmSJEmSqp2FkYaFhgao6fNuX2QReOut4vJIkiRJklTNLIw0LLS2QmMj1NbCCivAtGlwzTVFp5IkSZIkqTrVFR1AqoT6emhr6z2fNAnGjs2P33sPRowoJpckSZIkSdXIEUYalnrKojvvzNPV7rmn2DySJEmSJFUTCyMNa0sumXdO22ILuO66otNIkiRJklQdLIw0rI0bl0cZrb46fPrTcO65RSeSJEmSJKl4FkYa9lZcEW65BTbbDPbdF66/vuhEkiRJkiQVy0WvJfLUtKuvhtNOg622KjqNJEmSJEnFcoSRVLLQQnDooVBbC089lR+/+27RqSRJkiRJqjwLI2kWrr8eTj0VdtgBXnut6DSSJEmSJFWWhZE0C/vvD3/7G9x6K2y+OUydWnQiSZIkSZIqx8JIGsC++8KVV8Kjj8LHPw6TJxedSJIkSZKkyrAwkmbjU5+Cm2+GlVeGnXaCujpoaoLOzqKTSZIkSZJUPhZG0gf46EfhlVdg0iTo6oKJE6GlpehUkiRJkiSVj4WRNAc6OqC7Oz9OKZdGM2YUm0mSJEmSpHKxMJLmQEMD1JT+bYnIpdGnPw0vv1xsLkmSJEmSysHCSJoDra3Q2Ai1tTBuHBx/fF7bqLkZ2tqKTidJkiRJ0oJVV3QAaTCor39/MbTVVnDggbDIIsVkkiRJkiSpXBxhJM2jjTeG++/PZVJKcN55eVFsSZIkSZIGu7IVRhFxZkQ8HxEP9bn2y4hoj4gHIuLSiFiyXK8vVULPukZXXw2f/zzstFPeUU2SJEmSpMGsnCOMzga2n+nadcDaKaV1gUeA75Xx9aWK2WEHOO00uOEG2Ggj1zWSJEmSJA1uZSuMUkq3AC/PdO3alFLPZuR3ASuX6/WlSvvKV+DGG+GNN/J0tdbWohNJkiRJkjRvilzD6ADgqoFuRsRBETEhIia88MILFYwlzbvNNoMJE2DddWHUqKLTSJIkSZI0bwopjCLiKGAGcO5Az0kpnZ5Sak4pNY8ePbpy4aT5tPLKcNttsM02+fzCC+G114rNJEmSJEnS3Kh4YRQR+wM7AZ9PKaVKv75UCRH5+MQTeTHsj30MOjqKzSRJkiRJ0pyqaGEUEdsD3wF2TilNq+RrS0UYMwauvRZeegmam/N5XR00NUFnZ9HpJEmSJEmatbIVRhHxd+BOoCEinoqILwO/BRYHrouI+yLitHK9vlQtttwS7r4bZsyAJ5+Eri5ob4eWlqKTSZIkSZI0a3Xl+sIppX1mcfmMcr2eVM3GjIH33us97+52ipokSZIkqXoVuUuaNKw0NEBN6d+4mhpYfnnYb788XU2SJEmSpGpiYSRVSGsrNDZCbW0+fuELcN55MH583knNJeAlSZIkSdXCwkiqkPp6aGvLaxm1tcHPfgYTJsAqq8Cee8JnPgNTpxadUpIkSZIkCyOpUOutB3fdBb/4BVx9Nfz730UnkiRJkiTJwkgqXF0dfPvb8OijsNtu+doFF0BnZ7G5JEmSJEnDl4WRVCVWXDEfp02DQw6BddaBX/0KuroKjSVJkiRJGoYsjKQqM2oU3H03bLUVHHYYbLppXvNIkiRJkqRKsTCSqtAqq+Rd1c49FyZPhubmvL5RU1OewtbU5JQ1SZIkSVL5WBhJVSoCPvc5mDgR/vxnOOAAaG/PU9Ta26GlpeiEkiRJkqShysJIqnKjR8PnPw8dHdDdna91d+dzSZIkSZLKwcJIGiQaGqCmz7+xNTVw663F5ZEkSZIkDV0WRtIg0doKjY1QWwurrgrLLQebbw5HHll0MkmSJEnSUFNXdABJc6a+vv9uaW+9BUcdBSuvXFwmSZIkSdLQZGEkDVKLLgq/+lXv+XnnwY03woknwpJLFpVKkiRJkjQUOCVNGiKmTIGzzoKmpjx9TZIkSZKkeWVhJA0R3/se/PvfsPTSsPPOeWe1F18sOpUkSZIkaTCyMJKGkOZmmDABjjkGLrwQbrut6ESSJEmSpMHIwkgaYkaOhKOPhkmTYNdd87XLLoNnnikylSRJkiRpMLEwkoaoVVfNx9dfh/33h4YGWGklqKvL6xx1dhYaT5IkSZJUxSyMpCFuiSXy2kYzZsDUqdDVBe3t0NJSdDJJkiRJUrWyMJKGgYYGmD6997y7Gzo6issjSZIkSapuFkbSMNHQADWlf+Mj8jnAe+8Vl0mSJEmSVJ0sjKRhorUVGhuhthbGjcvnN94I48fDHXcUnU6SJEmSVE0sjKRhor4e2tryWkZtbfl8kUXymkaf+AQcdVT/aWuSJEmSpOHLwkgaxjbZBO67D/bbD44/Pp9PnFh0KkmSJElS0SyMpGFuiSXgzDPh4othyhS47rqiE0mSJEmSilZXdABJ1eEzn8lT05ZeOp//6195YewVVyw2lyRJkiSp8hxhJOn/Gz0676Q2fTp84Quwzjpw0UVFp5IkSZIkVZqFkaT3GTky76C2xhqwxx55jaPXXis6lSRJkiSpUiyMJM3SWmvB7bfDj34E554L48dDYyPU1UFTE3R2Fp1QkiRJklQuFkaSBjRiBBx7LNx2W56mNmkSdHVBezu0tBSdTpIkSZJULhZGkj7QxhvDK69Ad3c+7+6Gjo5iM0mSJEmSysfCSNIcaWjIC2L36O6GP/0JUioukyRJkiSpPCyMJM2R1ta8hlFtLYwdm0cdHXQQ7L47vPRS0ekkSZIkSQuShZGkOVJfD21tMGMGPPJIXtfoF7+AK66A3/ym6HSSJEmSpAWprugAkganmhr49rdhu+3ydDWAyZNhzBgYObLYbJIkSZKk+eMII0nzZd11YaGF4J13YNttYZNNXBBbkiRJkgY7CyNJC8TCC8Mpp8Djj8MGG7ggtiRJkiQNZhZGkhaY3XaDBx/Mo4x6FsR+882iU0mSJEmS5paFkaQFasUV4dpr4cQT8zS1UaOKTiRJkiRJmlsWRpIWuJoaOOIIuPLK/HjqVPjGN2D8eKirg6Ym6OwsOqUkSZIkaSDukiapbCLy8dJL4be/7b3e3g4tLdDWVkwuSZIkSdLsOcJIUtkdfHAeadSju9ud1CRJkiSpmlkYSaqIxsb+pdGHP1xcFkmSJEnS7FkYSaqI1tZcGtXWwiqrwDXX5OtTpsC0acVmkyRJkiT15xpGkiqivv79axalBLvvDq+8AqefDttsU0w2SZIkSVJ/jjCSVJgIOPHEPFVt223hy1/O5ZEkSZIkqVgWRpIKteWW8MADcOSR8Je/wPjx7p4mSZIkSUWzMJJUuEUWgZ//HP77X9hqK1hzzXy9u7vYXJIkSZI0XFkYSaoa668P550HCy0Er78O660Hf/pTXutIkiRJklQ5FkaSqtIbb8Ayy8BBB8HWW8PkyUUnkiRJkqThw8JIUlVaaSW48ca8e9q990JTEyy3HNTV5cednUUnlCRJkqShy8JIUtWKgAMPhIcfztPUnn8eurqgvR1aWopOJ0mSJElDl4WRpKq34oowbVrveXd3Lo1c20iSJEmSysPCSNKg0NAANaX/YkXk0miPPeDll4vNJUmSJElDkYWRpEGhtRUaG6G2Nh+//W34xz/yTmo33VR0OkmSJEkaWspWGEXEmRHxfEQ81OfaUhFxXURMKh0/XK7XlzS01NdDWxvMmJHXNPrFL+DOO2GRRfIuav/3f0UnlCRJkqSho5wjjM4Gtp/p2neBG1JKY4EbSueSNE+am+Gee/Joo+22y9dc10iSJEmS5l/ZCqOU0i3AzKuL7AL8pfT4L8Cu5Xp9ScPDYovBCSfAkkvCu+/CFlvAmWdaHEmSJEnS/Kj0GkbLpZSeKT1+FlhuoCdGxEERMSEiJrzwwguVSSdpUHvjDairgy9/GfbcE155pehEkiRJkjQ4FbbodUopAQOOAUgpnZ5Sak4pNY8ePbqCySQNVsssA9ddBz//OVx2Gay7Ltx8c9GpJEmSJGnwqXRh9FxErABQOj5f4deXNMTV1sKRR/YuiH3oodDdXXQqSZIkSRpcKl0YXQ7sV3q8H/CPCr++pGGiZ0Hsyy6Dmhq4/34YOzZPWWtqgs7OohNKkiRJUvUqW2EUEX8H7gQaIuKpiPgy8HPgkxExCdi2dC5JZbHYYrDaavnxVlvB5MnQ1QXt7dDSUmg0SZIkSapqdeX6wimlfQa4tU25XlOSBvL6672Pu7uho6O4LJIkSZJU7Qpb9FqSKqmhIU9N69HVBeecU1weSZIkSapmFkaShoXWVmhszItiNzTA5z4HW2yR7731FqQB92yUJEmSpOGnbFPSJKma1NdDW9v7r6cEu+wCCy8Mv/kNrL565bNJkiRJUrVxhJGkYa27Gz79abjpJhg/Hn76U3j33aJTSZIkSVKxLIwkDWu1tXD44XnntJ12gh/8ANZbDyZOLDqZJEmSJBXHwkiSgJVXhgsvhH/+E5ZfPp+DaxtJkiRJGp4sjCSpjx12yNPTFl8cpk+HTTeF3/0u76omSZIkScOFhZEkDeDVV2GxxeCQQ+AjH8kLZ9fVQVMTdHYWnU6SJEmSysfCSJIGsOyycM01cP75eY2jxx7LI43a26Glpeh0kiRJklQ+FkaSNBsRsNde/dcy6u6Gjo48ZU2SJEmShiILI0maAw0NUFP6L2ZNDay5Zp6i9t3vwksvFZtNkiRJkhY0CyNJmgOtrdDYCLW1+Xj22bD55vCLX8Dqq8OPfpTXPJIkSZKkoSDSINgzurm5OU2YMKHoGJL0Pg89BMccAxdfDEsumdc3Wm65olNJkiRJ0geLiLtTSs2zuucII0maD2uvDRddBPfeC9/6Vm9ZdPXV8NZbxWaTJEmSpHllYSRJC8BHPgJHHZUfT52ad1FbYw341a/gnXeKTCZJkiRJc8/CSJIWsBVXhJtugqYmOOywXBz9+McwfjzU1eXrnZ1Fp5QkSZKkgVkYSVIZbLop3HAD/OtfeTe1o4+Gjg7o6srrHLW0FJ1QkiRJkgZmYSRJZbTllnDLLXl3te7ufK27O5dGXV2FRpMkSZKkAVkYSVKZRUBDA9T0+S9ud3eemvZ//9dbJEmSJElStbAwkqQKaG2FxsY80mj8ePjd7/J6RnvvnRfMfvjhohNKkiRJUi8LI0mqgPp6aGuDGTPy8etfh/vvh/POg8UWg5VXzs974QVIqdiskiRJkmRhJEkFqa2FffaBO+6AJZbIaxptuWVeMPv66y2OJEmSJBXHwkiSqkRKcOih8OST8MlPwlZbwa23Fp1KkiRJ0nBkYSRJVaKuDg46CCZNglNPhY4O2HxzuOqqopNJkiRJGm4sjCSpyiy8MHzjG/Doo/CHP+TRRp2dMGZMnsbW1JTPJUmSJKlcLIwkqUqNGgVf/WoeedTSkqeqdXfnHdW2377odJIkSZKGsgELo4hYYjb3xpQnjiRpVjo6+p9PmgSHHQYvvVRMHkmSJElD2+xGGN3U8yAibpjp3mXlCCNJmrWGBqgp/Re7pgaWXDKvc3TffUWmkiRJkjRUza4wij6Pl5rNPUlSmbW2QmNjXsOosRHuvjuvcbTNNvn+CSfAX/4CXV3F5pQkSZI0NMyuMEoDPJ7VuSSpjOrroa0NZszIx/p6WG21fK+rC664AvbfHzbYAK65BpL/lZYkSZI0H2ZXGC0bEYdHxBF9Hvecj65QPknSB6ithZtvhvPPhzfeyAtif+pT0N5edDJJkiRJg9XsCqM/AYsDi/V53HP+5/JHkyTNqZoa2GsvmDgRfvUrePBBiNLkYUcbSZIkSZpbkQbB3ySam5vThAkTio4hSYPG9OkwcmR+vM8+sNJK8LnPwRe+kHdca2jI6yLV1xebU5IkSVJxIuLulFLzrO4NOMIoIg6MiLGlxxERZ0bEaxHxQESsX66wkqT511MWzZgBo0bBySfDhhvmEUhdXXm6WktLsRklSZIkVa/ZTUk7FHi89HgfYD2gHjgcOLW8sSRJC0JdHZxxBtx/f56a1jOotLs7jzSSJEmSpFmZXWE0I6X0XunxTsBfU0ovpZSuBxYtfzRJ0oKyzjowblzvukY1NXla2qOPwrRpxWaTJEmSVH1mVxh1R8QKEbEwsA1wfZ97i5Q3liRpQWttzaVRbS00NsLll+eFsuvr4ZRTLI4kSZIk9ZpdYfQjYAJ5WtrlKaU2gIjYAugsfzRJ0oJUXw9tbXldo7Y2WGONvLZRUxMcfrjFkSRJkqReAxZGKaUrgFWBcSmlA/vcmgDsVe5gkqTy23xzuOEGuPnm3uLonHOKTiVJkiSpaHUD3YiIz/R5PKunXFKOQJKkyuspjm67Le+mBrk4ev55+OpX805rkiRJkoaP2U1Juwj4AXnB652Alj4fO5U/miSp0jbbDBZaKD++/no44ghYfXU46SR46KE8CqmuLh87nZwsSZIkDVmRevZYnvlGxK7A3sCawD+Av6eUJlcuWq/m5uY0YcKEIl5akoa1226DY4/N5VFtLXR3Q0p5l7XGxrwWkiRJkqTBKSLuTik1z+re7NYwuiyltDewBfAocFJE3FZa9FqSNAxsthlcdx3ceit0deWyCHJx1NFRbDZJkiRJ5TO7KWk93gFeA14HFgMWLmsiSVLV2WwzGD8+jywCiMiPzzor77omSZIkaWgZsDCKiK0j4nTgbmAr4NcppY+klK6pWDpJUtVobc3T0GprYcwYaGiAAw6AtdeGCy7Io44kSZIkDQ2zG2F0PbARcBuwEPDFiDi156Mi6SRJVaO+Pq9ZNGMGPP44PPAAXHJJXgR7r73g8MOLTihJkiRpQambzb0vVSyFJGnQiYDddoOdd4bzz4f11svXOzthyhTYaqti80mSJEmadwMWRimlvwx0LyLGlCeOJGmwqa2Fz3++9/zkk+F3v4NttoGf/hQ+9rHiskmSJEmaN7Nd9DoiNomIz0bEsqXzdSPiPOD2iqSTJA06J56YS6MHHoCNN84jkB54oOhUkiRJkubG7Ba9/iVwJrA7cGVEHAdcC/wbGFuZeJKkwWbhheGww/LUtOOOg1tugdNPz+dNTXnNo6amfC5JkiSpOkVKadY3Ih4GNkgpvRMRHwaeBNZOKT1ewXwANDc3pwkTJlT6ZSVJC8DLL0NKsPnmMHFiflxTk3dca2srOp0kSZI0fEXE3Sml5lndm92UtHdSSu8ApJReASYVURZJkga3pZaCpZeGjo5cFgF0d+fy6OWXi80mSZIkadZmVxjVR8TlPR/A6jOdS5I0xxoa8siiHilBfT389rfFZZIkSZI0awPukgbsMtP5SeUMIkka2lpboaUljzRqaMiLY592GrzzTr7f3Q1dXTBiRLE5JUmSJM2mMEop3VzJIJKkoa2+/v1rFu2wQ+80tfPOg2OOyQtl77ln/9FIkiRJkiqrkF/HI+KwiGiLiIci4u8RsXAROSRJxYvIxxVXhFGjYJ99oLkZrrmmt0ySJEmSVFkVL4wiYiXgf4HmlNLaQC2wd6VzSJKqy9Zbw333wd/+Bq+8AttvDwcdVHQqSZIkaXgqasB/HbBIRNQBo4CpBeWQJFWRmhrYd9+8ztFvfgO7lFbTe/NNuPZaaGqCurp87OwsNqskSZI0lEUaYLx/RLQCA04GSCntPM8vGnEo8FPgbeDalNLnZ/Gcg4CDAMaMGfPRKVOmzOvLSZIGueOPh6OO6j2vqYHGxveviSRJkiRpzkXE3Sml5lndm90IoxPJO6M9Ri52/lT6eBN4dD7CfJi8A9vqwIrAohGx78zPSymdnlJqTik1jx49el5fTpI0BBx0UO9aR5B3VOvoKC6PJEmSNNR94C5pEXHSTG1Ta0RMmI/X3BZ4LKX0QunrXwJ8HDhnPr6mJGkIW2YZGDcO2ttzWQSw+OLFZpIkSZKGsjlZw2jRiKjvOYmI1YFF5+M1nwA2johRERHANsDE+fh6kqRhoLU1T0OrrYWVV4bzzsvXX3oJXn652GySJEnSUDPgCKM+DgNuiohOIIBVga/M6wumlP4dERcB9wAzgHuB0+f160mShof6+lmvWXT44XDVVXDSSXnB7L5T1yRJkiTNmwEXve73pIiFgMbSaXtK6d2ypppJc3NzmjBhfmbBSZKGqvvvh69+Fe66C7bcEv7whzwSSZIkSdLszeui1z2fPAr4NnBISul+YExE7LSAM0qSNE/WWw9uvx3++Ee47z5Yd1248MKiU0mSJEmD25ysYXQWMB3YpHT+NHBc2RJJkjSXamryTmodHbD//rDZZvn6tGmFxpIkSZIGrTkpjNZIKf0CeA8gpTSNvJaRJElVZdll4fTTYYUV8m5q220He+wBTz9ddDJJkiRpcJmTwmh6RCwCJICIWAOo6BpGkiTNre5u2H57uOKKvKbRD38I48dDXR00NUFnZ9EJJUmSpOo1J4XRMcDVwCoRcS5wA/CdcoaSJGl+1dXBUUflndU+8Qk47jiYOBG6uqC9HVpaik4oSZIkVa853SVtaWBj8lS0u1JKL5Y7WF/ukiZJmh8p5QKpu7v3Wm0tvPYaLLpocbkkSZKkIs3vLmk3AB9LKV2ZUroipfRiRJy+wFNKklQmEXlaWk3pp15NTf5YeWU44gh49NFi80mSJEnVZk6mpK0OHBkRR/e5Nsv2SZKkatXamkuj2tp8POecvCj2qafC2LGw447wn/8UnVKSJEmqDnVz8JxXgW2AUyOiFdi3rIkkSSqD+vq8nlFfe+4JU6fCH/+YP55/Pl9/+eU8AmnJJSseU5IkSaoKczLCKFJKM1JKXwcuBm4Dli1vLEmSKmPFFeHYY+GJJ2CHHfK1E0+ElVaCr34VHnqo2HySJElSEeakMDqt50FK6Wxgf+DaMuWRJKkQI0fm6WqQRx7ttRecfTassw5stRWcdho0NeXFs5uaoLOz0LiSJElSWQ24S1pELJFSej0ilprV/ZTSy2VN1oe7pEmSivDSS3DGGfD738Mrr8Cbb+ad1mpq8jpIM09xkyRJkgaT2e2SNrvC6IqU0k4R8RiQgOhzO6WU6hd81FmzMJIkFamrCxZaKB97RMAdd8DHPpYfS5IkSYPN7AqjAaekpZR2Kh1XTynVl449HxUriyRJKlptLTQ05JFFkAuiCNhkE9hwQzjrLHjnnWIzSpIkSQvSgIVRRGwwu49KhpQkqWitrXkaWm0tjBsH996bp6q9/TYcckg+AkyfXmxOSZIkaUGY3ZS0f83m81JKaevyRHo/p6RJkqpVSjB5Mowdmx9vvDEst1wukbbdtndUkiRJklRtZjclrW6gT0opbVW+SJIkDQ0RuSwCmDEDPvUpOP30PCJp7Fg4+GDYbz9YcslCY0qSJElzZY7+v2dErB0Re0bEF3s+yh1MkqTBZsQI+MlP4Ikn4NxzYZll4JvfhIsvhs5OaGqCurp87OwsOq0kSZI0sAGnpP3/J0QcDWwJjAf+CewA3JZS+mzZ05U4JU2SNFjdc09e+2jDDWHixDxtLSJfe/jhotNJkiRpOJunXdL6+CywDfBsSulLwHrAhxZgPkmShqwNNoBRo6CjI5dFkI8TJ8KPfwzPPltsPkmSJGlW5qQwejul1A3MiIglgOeBVcobS5KkoaWhoXcB7AhYdFE4+mjYd99ic0mSJEmzMieF0YSIWBL4E3A3cA9wZzlDSZI01LS25mlotbUwbhw88AA88gj88pf5/rPPwkYbwZ//DNOmFZtVkiRJ+sA1jPo9OWI1YImU0gNlSzQLrmEkSRrq7rkH9t8fHnww76h2wAHwta/BmmsWnUySJElD1fyuYURErBsROwMbAGtGxGcWZEBJkoa7DTaA+++HW26B7baDU0/NI5Kef77oZJIkSRqO6j7oCRFxJrAu0AZ0ly4n4JIy5pIkadiJgE98In9MnQo33QTLLpvv7bsvXH89vPhiXg+ptRXq6wuNK0mSpCHsA6ekRcTDKaXxFcozS05JkyQNZ9Onw4c/3H9to/p6ePTR4jJJkiRp8JvfKWl3RkShhZEkScPZyJHw7rv9r3V2wtlnFxJHkiRJw8CcFEZ/JZdGHRHxQEQ8GBEVXfRakqThrqEBako/tWtqYLnlYMcd8/kVV8CPf5x3WpMkSZIWhDkpjM4AvgBsD7QAO5WOkiSpQlpb8yLYtbX5eMcdMHp0vnfrrXD00TBmDHzuc/neXGyCKkmSJL3PnKxhdGdKaZMK5Zkl1zCSJGn2Jk2C3/8ezjoLXnsN9t4b/v73olNJkiSpms3vGkb3RsR5EbFPRHym52MBZ5QkSfNh7Fg45RR46ik47TT4TOkn9ZtvwlFHwS23QFMT1NXlY2dnsXklSZJU3eZkhNFZs7icUkoHlCfS+znCSJKkeXPNNXmto66u3ms1NXlaW1tbcbkkSZJUvNmNMKr7gE+sBV5KKX2rLMkkSVJZbbcdPPYYrLpq77pG3d3Q0VFsLkmSJFW32U5JSyl1AZtWKIskSSqDVVaBceN6d1mDvOsa5ClrkiRJ0szmZA2j+yLi8oj4gmsYSZI0OPXdZW38+Hz+1FO5TPrWt+CVV4pOKEmSpGoyJ4XRwsBLwNZAS+ljp3KGkiRJC1Z9fV6zaMaMfKyvhxEjYLfd4OSTYY018vHdd4tOKkmSpGrwgYteVwMXvZYkqXweeACOPBKuvjoXRw88AKNGFZ1KkiRJ5Ta7Ra8/cIRRRKwcEZdGxPOlj4sjYuUFH1OSJBVh3XXhqqvguuvggAN6y6KJE4vNJUmSpOLMyZS0s4DLgRVLH62la5IkaQjZdlv4/vfz47vvzmsd7bwzPPxwsbkkSZJUeXNSGI1OKZ2VUppR+jgbGF3mXJIkqUDjx8PPfgY33wzrrAP77JN3Vqurg6Ym6OwsOqEkSZLKaU4Ko5ciYt+IqC197EteBFuSJA1RiywC3/0uTJ4MhxwC558PjzwCXV3Q3g4tLUUnlCRJUjnNSWF0ALAn8CzwDPBZ4EvlDCVJkqrD6NHw619DbW3vte7uvL7RXXfBINg7Q5IkSfPgAwujlNKUlNLOKaXRKaVlU0q7ppSeqEQ4SZJUHRoaoKb0W0NNDUTAJpvABhvA6afDm28Wm0+SJEkLVt1ANyLiR7P5vJRS+kkZ8kiSpCrU2pqnoXV05PLo73+HO+6AP/wBvvIV+Pa34aabYP31i04qSZKkBWHAwgh4axbXFgW+DCwNWBhJkjRM1NdDW1v/a+uum8uiO+6Ac86BtdfO1889Ny+OvdtuMHJk5bNKkiRp/g1YGKWUTup5HBGLA4eS1y46HzhpoM+TJEnDRwRsumn+6PGnP+Xd1ZZbDv7nf+Cgg2DMmOIySpIkae7Ndg2jiFgqIo4DHiCXSxuklI5MKT1fkXSSJGnQufFG+Oc/YaON4PjjYfXV87GzE5qa8uijpqZ8LkmSpOo0YGEUEb8E/gu8AayTUjompfRKxZJJkqRBqaYGdtgBLr8cHnsMvvvdvEB2Swu0t0NXVz62tBSdVJIkSQOJNMB+uBHRDbwLzAD6PinIi14vUf54WXNzc5owYUKlXk6SJJVBXV0ui3pEwJQpsMoqxWWSJEkaziLi7pRS86zuDTjCKKVUk1JaJKW0eEppiT4fi1eyLJIkSUNDQ0MefdQjpTxdbb/98mNJkiRVj9muYSRJkrSgtLZCYyPU1sL48XDLLfDNb8Lii+fRRgC33grd3YXGlCRJErPZJU2SJGlBqq+Htrb+1z7xid7H998Pm28Oa64Jhx2WRx4tumhlM0qSJClzhJEkSaoKTU1wwQWw9NJw8MF5baPvfx9efbXoZJIkScOPhZEkSaoKdXWwxx5w551w++2w1Vbwhz/0Tld78MFcKtXV5WNnZ7F5JUmShrIBd0mrJu6SJknS8PTaa/ChD+VFsRdZBN59N1+vqcnrIc08xU2SJElzbp52SSuniFgyIi6KiPaImBgRmxSRQ5IkVbcPfSgfZ8yA6dN7r3d3w8SJeZFsSZIkLXhFTUn7NXB1SqkRWA+YWFAOSZI0CIwYAePG5ZFFkKep1dTAE0/k86lT4cIL4a23issoSZI0lFS8MIqIDwGbA2cApJSmp5RerXQOSZI0uLS25mlotbW5PJo4EfbcM9+7+OL8eNllYa+98vm0acXmlSRJGswqvoZRRHwEOB14mDy66G7g0JTSWzM97yDgIIAxY8Z8dMqUKRXNKUmSBo+urjw97YIL4KKL4IUXYIkl4OmnYbHFik4nSZJUnaptDaM6YAPgDyml9YG3gO/O/KSU0ukppeaUUvPo0aMrnVGSJA0itbWw5Zbw+9/n6Wk33ABHH91bFn3mM7DLLjBmjLusSZIkzYkiCqOngKdSSv8unV9ELpAkSZLmW10dbL01HH54Pk8JllsOrrgCnnwyj0aaOBF23LHYnJIkSdWs4oVRSulZ4MmIaChd2oY8PU2SJGmBi4A//CEfe6QEHR3FZZIkSap2Re2S9g3g3Ih4APgIcHxBOSRJ0jDR0NB/l7WG0v+6uvhiOOwweOqp4rJJkiRVm0IKo5TSfaX1idZNKe2aUnqliBySJGn4mHmXtSuvzNcfegh+8xuor4cvf9mRR5IkSVDcCCNJkqSKqq+HtjaYMSMf6+vz9aOPhsmT4StfgfPOy2XSd75TbFZJkqSiWRhJkqRhb7XV8iijKVPge9+Dj340X3/zTbjxxrzmkSRJ0nBiYSRJklSy7LLw05/CXnvl87POgm22gY03htNOg6amvAtbUxN0dhabVZIkqZzqig4gSZJUrQ48EEaMgF/+Er72td7r7e3Q0pKntkmSJA1FjjCSJEkawMILw1e/mhfCrunzW1N3d77W1VVcNkmSpHKyMJIkSfoAdXV5h7We0qimBtZYIy+cfcIJ8PrrxeaTJEla0CyMJEmS5kBray6Namvz8fe/zzuqffe7MGYM/OAH8MILRaeUJElaMCINgm0/mpub04QJE4qOIUmS9D533w0//zlcfDEsuig8+SQsuWTRqSRJkj5YRNydUmqe1T1HGEmSJM2Hj34ULrwQHn4YTjyxtyw69dS8zpEkSdJgZGEkSZK0ADQ2wle+kh8/91yeqjZuHOyxB9xzT7HZJEmS5paFkSRJ0gK23HLw+OO5NLr22jwKafPNYezYvIB2UxN0dhadUpIkaWAWRpIkSWWw7LJw/PHwxBPws5/BXXflkqirC9rboaWl6ISSJEkDszCSJEkqow99KI806u7OH5CPDz8MF13Ue02SJKmaWBhJkiRVQEMD1JR+84qAESPy+kZrrw1/+xvMmFFsPkmSpL4sjCRJkiqgtTUvjF1bmxfDbmuD88/PxdEXvwjnnFN0QkmSpF51RQeQJEkaDurrc0nU19ixsOee8M9/wrbb5mvnnAPPP593XFt00crnlCRJAkcYSZIkFSoCdtwRFloon193HRxxBKy6Khx3HLz6aqHxJEnSMGVhJEmSVEX+8he44w7YeGP44Q9zcfSnPxWdSpIkDTcWRpIkSVVmk03giivgnntgu+1g+eWhszOvgVRXB01N+VySJKlcXMNIkiSpSq2/PlxwQX7c1ASPPAIpwcSJ8OlPQ3t7sfkkSdLQ5QgjSZKkQaCjI5dFkI8dHXDssfDGG8XmkiRJQ5OFkSRJ0iDQ0AA1pd/campg8cXhmGPg618vNJYkSRqiLIwkSZIGgdbWvIZRbW0+3ncf/Pvf8IMf5PuTJ8NZZ8GMGYXGlCRJQ4SFkSRJ0iBQXw9tbbkQamvL5xttlEceAZx9NhxwAKyzDlxySe/0NUmSpHlhYSRJkjQE/OQncPHFEAG77w4f+xjceGPRqSRJ0mBlYSRJkjQERMBnPgMPPABnngnPPQeXXlp0KkmSNFhZGEmSJA0hdXXwpS/BI4/Accfla7fcAtttB2uume83NUFnZ7E5JUlSdasrOoAkSZIWvIUWyh8Ajz8O118P3d35vL0dWlryWkiSJEmz4ggjSZKkIe6LX8xT1np0d+fSSJIkaSAWRpIkScNAQwPU9PnNb/To4rJIkqTqZ2EkSZI0DLS2QmMj1Nbm8ui22/L122+HF18sNpskSao+rmEkSZI0DNTXv3/Nonfegc9+NpdI550Hm29eTDZJklR9HGEkSZI0TC28MFx5JSyyCGy1Ffz4x9DVVXQqSZJUDSyMJEmShrENNoB77oF99oGjj4Ztt4Vp04pOJUmSiuaUNEmSpGFu8cXhb3+DT34S7rgjjziSJEnDmyOMJEmSRATstx/88Y/58cMPw5FHwvTpRSeTJElFsDCSJEnS+1x5JfziF7DZZtDZWXQaSZJUaRZGkiRJep9vfxsuvhgmTYKPfAT+7/+KTiRJkirJwkiSJEmz9JnPwL33wtprw957w8orQ10dNDU56kiSpKHOwkiSJEkDWm01uPlmWG45eOYZ6OqCiRNhxx2LTiZJksrJwkiSJEmzNWIEvPgidHfn85SgvR323x9uvz2fS5KkocXCSJIkSR+ooQFqSr85RsCHPwyXXJIXxW5qgtbWYvNJkqQFy8JIkiRJH6i1FRobobYWxo2DCRNg6lQ44wz40IfydYAnnoAbbugdjSRJkganSINgDHFzc3OaMGFC0TEkSZI0gJTyyKMf/hCOOw7q6+F//idPW1thhaLTSZKkWYmIu1NKzbO65wgjSZIkzbeIfDzqKDj3XBgzBr7/fVhllbzD2qOP5qlr7rImSdLg4AgjSZIklcWkSfDnP8Pbb+dpau3teapaTU2e3tbWVnRCSZKGt9mNMKqrdBhJkiQND2PHwgkn5Md1db3rGnV3w8MP5/WP9tgDlliiuIySJGnWnJImSZKkspt5l7WRI/MaR8svDzfeWGw2SZL0fhZGkiRJKruZd1l7+GG46y444AD46Efzc845B448Mt+TJEnFckqaJEmSyq6+/v1rFq2xBnzsY73nDz4IJ50Ev/gFNDfDfvvBPvvA0ktXNqskSXKEkSRJkqrECSfA00/DySfDe+/BN74Bn/1s7/3Jk91pTZKkSnGXNEmSJFWl++/PO6xtvDG8+CKssAJ0dUFK7rQmSdKC4C5pkiRJGnTWW6/38Rtv9JZFkHdaa2/P5xHF5JMkaShzSpokSZKq3uqr58Wya/r89trd7bQ0SZLKxcJIkiRJg8LMO6395S954WyAAw+EH/wApk4tNqMkSUNFYYVRRNRGxL0RcUVRGSRJkjR49Oy0NmMGPPwwfPGL+XpXF7z8Mhx/PKy6Kuy7L7j8pSRJ86fIEUaHAhMLfH1JkiQNAbW1cPHFMGkSHHIIXH45bLgh/PGPRSeTJGnwKqQwioiVgR2BPxfx+pIkSRp61lgDTjkFnnoqH3fZJV+/9lo46aS861pTE9TV5aPrH0mSNLCidkn7FfAdYPGBnhARBwEHAYwZM6YyqSRJkjToLbEEfPObvedXXQW/+lXvbmop5R3WWlryFDdJkvR+FR9hFBE7Ac+nlO6e3fNSSqenlJpTSs2jR4+uUDpJkiQNNaecAneXfvNMKR+7u6Gjo7hMkiRVuyKmpG0K7BwRjwPnA1tHxDkF5JAkSdIwscEGeWe1mtJvvxHQ0ABvvw1nnZWPkiSpV8ULo5TS91JKK6eUVgP2Bm5MKe1b6RySJEkaXlpbobExL5I9blw+b22FAw6AMWPghz+EZ54pOqUkSdWhyF3SJEmSpIqpr89rFs2YkY/19bDHHnDjjfDxj8NPfwqrrgpf+AJMm1Z0WkmSilVoYZRSuimltFORGSRJkjR8RcBWW8E//gGPPAJf+1reZW2RRfL9++7LBZMkScONI4wkSZIkYM014de/ziOOIuCVV2DTTfP1k07K5VFTE9TV5WNnZ9GJJUkqHwsjSZIkqY+IfFxiCTj3XFhtNfjWt/LC2RMnQlcXtLdDS0uhMSVJKisLI0mSJGkWamth113hppvgnnvytZTysbsbOjqKSiZJUvlZGEmSJEkfYP31885qNaXfnmtqYNFFYYst4IorcoEkSdJQYmEkSZIkzYHWVmhszCOPGhvhm9+Exx7LU9PWWQfOOgvefbfolJIkLRgWRpIkSdIcqK+Htra8a1pbGxx7LDz6KPztb3kh7AMOgJ//vOiUkiQtGBZGkiRJ0jwaMQL23TfvoHbNNXDQQfn6ddfBt78NTz1VaDxJkuaZhZEkSZI0nyLgU5+CFVbI5xMmwCmn5FFJ++8PDz1UaDxJkuaahZEkSZK0gH3vezB5Mnzta3DhhXmNo733hqamPH2tqQk6O4tOKUnSwCyMJEmSpDJYbTX49a/hiSfgxz+GW26B9nbo6oKHH4bNNoNHHoGUik4qSdL7WRhJkiRJZbT00vDDH8Lzz0N3d+/1Z56BhoY8jW3PPeGBB4rLKEnSzCyMJEmSpApoaICa0m/fNTWwxhpw+umw7bZw5529I43+8Q/YZRc4+eS8FtKMGcVlliQNXxZGkiRJUgW0tkJjI9TW5uO118KBB8I55+Rpa+uum5/3+ut5ytoRR8CGG8JSS8EOO+SFs10DSZJUKZEGwaTp5ubmNGHChKJjSJIkSRXz9NNw66157aNJk2Dq1LwGUs+0ttGj4fzzYeONYdSoYrNKkganiLg7pdQ8y3sWRpIkSVL1q6vLC2bPbMQI+Nzn4Oyz8/nbb8Mii1Q0miRpkJpdYVRX6TCSJEmS5l5DQ+8Io5oaWGutvM7RLbfAcsvl58yYASuumHdo23zz/PGJT8CyyxYaXZI0CLmGkSRJkjQIzLwG0pVX5rWNfvYz+OY383PefRcOOyzvzPanP8FnP5vLpJNOymsejR/vGkiSpDnjlDRJkiRpCJo+He65J49A2mYb+OIXYeLEvBtbRN6lbdKkolNKkoo0uylpjjCSJEmShqCRI/OC2N/5Dnz0o9DRkcsiyMfJk2HfffPua5IkzczCSJIkSRoGGhry2keQj0svDZddBttvn9c+kiSpLwsjSZIkaRiYeQ2k//wHpkyBCy7I6xq99x58/vNwww29I5EkScOXhZEkSZI0DNTXQ1tbHk3U1pbPl14aPv7xfH/SJLjxRth22zyV7R//yDuySZKGJwsjSZIkSYwfD489BqedBi+8ALvuCuuuC888U3QySVIRLIwkSZIkAbDwwvCVr8Ajj8C550JTEyy/fL536aW5VKqry9c7O4vNKkkqr0iDYIJyc3NzmjBhQtExJEmSpGHpjTdgySV7p6jV1OR1kNraCo0lSZpPEXF3Sql5VvccYSRJkiRpthZbrP95dzdMnAgPP1xMHklS+VkYSZIkSZqtiDyiqKam9zwC3n47nz/1FLz4YnH5JEkLnoWRJEmSpA/U2ppLo9paGDcOHnoIPvrRfO+HP4SVVoLPfQ5uvhkGwaoXkqQPUFd0AEmSJEnVr75+4DWLvvUtWHxx+Otf4e9/h4YGOOIIOPDAymaUJC04jjCSJEmSNF+amuDUU2HqVDj7bFhqqd5yKSW4805HHUnSYGNhJEmSJGmBGDUK9tsP7rgDTjwxX/vXv+DjH4exY2H55aGuLhdMnZ3FZpUkzZ6FkSRJkqQFrq60+MXHPgZnnglPPw3PPQddXXl3tR12KDafJGn2LIwkSZIklc2ii8KXvgTvvdf/+qOP5uMFF8CVV8L06ZXPJkkamIWRJEmSpLJraICa0t8+amryOcAJJ8BOO8EKK8BXvgI33ZRHIUmSimVhJEmSJKnsWluhsRFqa/OxtTVfv/NOuOIK2H57OPdc2GorOPjg3s9zsWxJKkZd0QEkSZIkDX319b07p/U1ciTsuGP+mDYtF0mrrZbvtbdDSwvsvTdsthkcfjh0dOTRSa2t+WtKksrDwkiSJElSVRg1Cvbaq/d82rRcHh1/PHR3917vKZJmVUBJkhYMp6RJkiRJqkobbADXXZd3WKvp8zeX7u480qhviSRJWrAsjCRJkiRVteWXz+sezbxo9lZbwde/Do89Vmw+SRqKLIwkSZIkVb2ZF82+8MJcGp1xBowdC1/4glPUJGlBsjCSJEmSVPV6Fs2eMSMfx4+H00+Hzk449FC49FJYe2248sqik0rS0GBhJEmSJGnQWmklOOkkmDIlL469zTb5+hVX5PWPUio2nyQNVhZGkiRJkga9pZeG730PFl44n59wAnzqU7DRRnDJJS6QLUlzy8JIkiRJ0pBz/fV5ytorr8Duu8Naa8Gqq0JdHTQ15alskqSBWRhJkiRJGnIWWggOPBDa2+Hvf4ennoInn4Surnxtyy3hrbeKTilJ1cvCSJIkSdKQVVcHe++dF8vuWc+ouzuXR0stBdtuC7/8JTz4oOsdSVJfFkaSJEmShryGBqgp/e2npiZPT/vf/4XnnoPvfAeam2HatHy/rQ1efrm4rJJUDSyMJEmSJA15ra3Q2Ai1tfl44429I4uefBIuvRQWXTQ/98tfhtGjYZNN4Jhj4K678lS2zs68/pHrIEkaDiINgnGXzc3NacKECUXHkCRJkjQM/PvfcNVVcPXV8J//5Klqe+yRRx61t+cpbTU1uXhqays6rSTNu4i4O6XUPMt7FkaSJEmSNGsvvZR3XFt6adh++zzSqEdNDbz7bh5xJEmD0ewKI6ekSZIkSdIAll4a9torL47ddx0kyCONVlkFvvUteOaZ4jJKUjlYGEmSJEnSHOi7DtK4cfCHP8DGG8Nvf9s78uiRR+DFF4vNKUkLglPSJEmSJGk+vP46LLFEfrzDDnkK2447wv77w6c/DSNHFhpPkgbklDRJkiRJKpOesgjyzmvf/GZeOHu33WDFFfM1cJc1SYOLhZEkSZIkLSBrr50LoiefhCuvhG22gREj8r0dd4SJE/P0tfZ2aGkpNqskzY5T0iRJkiSpAmpr80LZPSLg9ttho43yPUmqtKqakhYRq0TEvyLi4Yhoi4hDK51BkiRJkiqtsbH/Lmspwcc/Dg8/nM+nToU33ywmmyTNrIgpaTOAI1JK44GNgYMjYnwBOSRJkiSpYvrusjZ+PNxzD1x0UZ7GBnDUUbD00nnh7N//Hp54oti8koa3ihdGKaVnUkr3lB6/AUwEVqp0DkmSJEmqpPp6aGuDGTPycf31Yffd89Q0gAMPhIMPhsmT83HVVWHnnXs/30WzJVVSoWsYRcRqwC3A2iml12e6dxBwEMCYMWM+OmXKlMoHlCRJkqQKSwk6OvKIpIUXhm98Iy+Uveii8O67+Tk1NXm0UltbsVklDW6zW8OosMIoIhYDbgZ+mlK6ZHbPddFrSZIkScPZyy/DMsvkMqmvG26ArbcuJpOkwa+qFr0GiIgRwMXAuR9UFkmSJEnScLfUUjBuXO+i2RGw0ELw3nv5/O674aCD4NJL4Y03isspaegoYpe0AM4AJqaUTq7060uSJEnSYNR30exx4/Luap/6VL7X3g7nnw+f+Uwul7baCn75S3ddkzTvKj4lLSI2A24FHgS6S5e/n1L650Cf45Q0SZIkSZq96dPhjjvgn/+Eq66Cxx+HF1/MI5EuvRSeew5+/WuYNAkaGnIBVV9fdGpJRarKNYzmhoWRJEmSJM2dl1/Oo40ANt00l0k9IvIoJRfNloa3qlvDSJIkSZJUXj1lEcC//tW7/hHkxbMnTqx8JkmDh4WRJEmSJA1xI0fm9Y/6Lpq96qr58ZQpecHs++8vLp+k6mNhJEmSJEnDwMyLZt9wQ74+YQKccw585COw2WZ58ezp0wuNKqkKWBhJkiRJ0jBQX5/XLJoxIx97FrzefXd46ik46SR49lnYZx9Yc014551i80oqloWRJEmSJA1zSy0Fhx8OjzySd1j73/+FhRfO9445Jq+BNAj2S5K0ALlLmiRJkiRpll5+GdZaC156CdZYA956C154ARoa8hS3nlFKkgYnd0mTJEmSJM21pZaCJ5+Es86Cp5/OU9a6uvIOay0tRaeTVE4WRpIkSZKkAS2yCOy/P7z3Xu+1lKCjw2lq0lBmYSRJkiRJ+kANDVBT+htkTU2eqrb55nDaadDdXWw2SQuehZEkSZIk6QO1tkJjI9TW5uNf/gIjR8LXvgZbbAHt7UUnlLQgWRhJkiRJkj5QfT20tcGMGfm44YZw/fVw5pn5fL314Cc/6T91TdLgZWEkSZIkSZonEfClL+VFsHfbDS66qOhEkhYUCyNJkiRJ0nxZbjk4/3y49VYYMQJefRW+9z14442ik0maVxZGkiRJkqQFYokl8vGaa+CEE6CpCa64othMkuaNhZEkSZIkaYHaay+4/XZYfHFoaYG994bnnis6laS5YWEkSZIkSVrgNtkE7r0Xjj0WLr0U/ud/8oijurp87OwsOqGk2bEwkiRJkiSVxciR8KMfwX33QUcHtLdDV1c+trQUnU7S7FgYSZIkSZLKaty4PKKouzufd3fn0khS9bIwkiRJkiSVXUMD1PT5G2h3N5x6KqRUXCZJA7MwkiRJkiSVXWsrNDZCbW0uj7bZBg49NC+I/cYbRaeTNLO6ogNIkiRJkoa++npoa+s97+6GX/4S/vxnmDGjuFySZs0RRpIkSZKkiqupgSOPhAcfhA9/GN59F664ouhUknpYGEmSJEmSCrPwwvn4+9/nndMOPjiXR5KK5ZQ0SZIkSVLhDjkEpk6FE0+ECRPgggtg1VWLTiUNX44wkiRJkiQVbsSIvKbRJZdAeztssAHcdFPRqaThy8JIkiRJklQ1dtstjzBqbIRlly06jTR8WRhJkiRJkqrK2LFw220wfjykBKecAi+8UHQqaXixMJIkSZIkVZ2IfJw0Cb73PVh3Xaivh7o6aGqCzs5i80lDnYWRJEmSJKlqrbUW3HEHvPQSPPYYdHXlNY5aWopOJg1tFkaSJEmSpKq2wQbQ3d173t0NHR358S235DJJ0oJlYSRJkiRJqnoNDVBT+htsRD6fPh0+/WkYPRqam/PUtRtvhHffLTarNBRYGEmSJEmSql5ra945rbYWxo3L53V1cP31cOyxMGoUnHgibLMNHH98/py334YHHsgLZ0uaO5EGwb85zc3NacKECUXHkCRJkiRVsTfegJtvzqOPxo6Fq6+GHXaA5ZaDj30MJkyA557L91tb8yLa0nAWEXenlJpnec/CSJIkSZI0FL34IlxxBVx7LVxwQV4wG/LUtsZG+NWv8hpIa63V+/HhDxcaWaooCyNJkiRJ0rBWV9dbGEGe2nb00Xk6W9/ryywDU6bkKW4335xLp7XWys/fY4+82LYjlDRUzK4wqqt0GEmSJEmSKq2hAdrb8w5rNTX5/Ic/hCOPhMceg0ceyR9PP53LIoDf/hYuuuj9X6u9HVpa4NxzYZFFYPXVYeTIyn4/Urk5wkiSJEmSNOR1duaSZ25GCL3xBkyalIukz32u/+LZtbV5Z7Z//zs/XnXVPBJpyy1zCQXwzDN5B7e6unl7fancnJImSZIkSdJ8aGrqP0KpsRH+8hd4+OFcKvV8jB8Pf/tb/pyVVoIXXsgjkKZOhbfeyqVTz+c/+GB+LBXFKWmSJEmSJM2H1tZZjxBqnuVftXMxdNxxeXRSzyilHt3d+essthiMGZN3dFtzzfyx5Za5nJKKZmEkSZIkSdIHqK+HtrY5f34EfOlLveczj1AaOxZ22QUmT86F0o03wrRpcMIJ+blPPgnbbNNbJo0dC4sumu9Pnuy0NpWfhZEkSZIkSWU20AilHinBs8/2Lp793nuw3nq5HLr55jydDXIRlRJMnAjrrAOf/Wye8rbaavm4wQaw+OIV//Y0BLmGkSRJkiRJVSwleO65vCZSd3f/eyuvnHd26/mr/a23wmabwRVXwCmn9C+TRoyAY47J0+McoSRwDSNJkiRJkgatCFh++bxQ9swLb7e1wfTp8MQT8PjjsO66+XNmzMhT3K64IpdNPWpq8udPnAjrrw+HHJJ3d1trrTztbeml8+tJjjCSJEmSJGkQ6Oyc/bS2gUybBlOmwNprv3+EUm0tdHXlxzU1+bkLLQTnnAOPPZZLpJ4y6YUX5u31Vb0cYSRJkiRJ0iA3twtv9xg1CsaNm/UIpfvuyyOTHnkEpk7NZRHAtdfC3/7W/+ssvHAezdQzQmnLLeFf/8pT3mpr5+97U/VxhJEkSZIkScPA3I5QmjYNHn00l0mTJsH3v9+7VlJfCy2URyDttBP87Gf52sSJeX0lF+Cubo4wkiRJkiRpmJvbEUqjRuWd2NZZJ5//7W/9RyiNGQM//GG+1nMdcqn08Y/Dq6/CiivmkUyNjXkHt5NPdkrbYOEII0mSJEmS9IHmdIRSdzdcfnlvkdTenkccjRgBr7zSWywtsQQcdxxsvDGstx6MHFnZ70ezH2FkYSRJkiRJksoqpVwY9SywPbOFF4azzoK994Y334TXXoOVVqpsxuFodoVRTaXDSJIkSZKk4SUij0qqKbUQNTUwfjw8+SRccAF8/et5FzeAq6/O6x+tsgrssQecdBLccUceqdTUBHV1+djZWdz3Mxw4wkiSJEmSJJXdnE5pe/zxPKXtrrvgzjvzOcCaa+av0d2dC6jVVoMHH4RFF63gNzHEOCVNkiRJkiQNSs8+C//9L+y22/untEXkImn99eHvf88jl15/Pe/OFlFM3sHEKWmSJEmSJGlQWn75PDJp5iltq6wCxxyTd3F77bXee3vuCUsuCZ/4BBxyCPzpT3DvvXl0klPa5lxd0QEkSZIkSZI+SGvrnE1p++IX8/UHHoC//hXeeAO22gqeey6vg9TdnXdt2247eOQRRyINxClpkiRJkiRpSOruzmsgvfVWnrY285S2FVfMZdJ++8EnP1lIxEJV3ZS0iNg+IjoiYnJEfLeIDJIkSZIkaWirqcmjjdZZ5/1T2lZYIU9bu/56aGvL1597Lo9QOvNMeOwxGARjbMqm4oVRRNQCvwN2AMYD+0TE+ErnkCRJkiRJw0drKzQ2Qm1tPt52G5x/PjzzDHz96/k5kyfD1VfDl7+ci6bVVoP994dJk4bfGkhFjDDaCJicUupMKU0Hzgd2KSCHJEmSJEkaJurr80iiGTPysWf9owgYOTI/3nTTPMrooYfgN7+BDTeEK67IJVNLS177qKsrr4XU0lLc91IJRSx6vRLwZJ/zp4CPzfykiDgIOAhgzJgxlUkmSZIkSZKGtYg8gqipKe+y1t2dr3V09E5R6+7O50NZIWsYzYmU0ukppeaUUvPo0aOLjiNJkiRJkoahmppcGM28BlJDQ7G5yq2IwuhpYJU+5yuXrkmSJEmSJFWlmddAam0tOlF5FTEl7b/A2IhYnVwU7Q18roAckiRJkiRJc6RnDaThouKFUUppRkQcAlwD1AJnppSG0R+5JEmSJElSdStihBEppX8C/yzitSVJkiRJkjR7VbvotSRJkiRJkophYSRJkiRJkqR+LIwkSZIkSZLUj4WRJEmSJEmS+rEwkiRJkiRJUj8WRpIkSZIkSerHwkiSJEmSJEn9WBhJkiRJkiSpHwsjSZIkSZIk9WNhJEmSJEmSpH4sjCRJkiRJktSPhZEkSZIkSZL6sTCSJEmSJElSPxZGkiRJkiRJ6sfCSJIkSZIkSf1YGEmSJEmSJKkfCyNJkiRJkiT1Y2EkSZIkSZKkfiyMJEmSJEmS1E+klIrO8IEi4gVgStE5SpYBXiw6hIY134Mqmu9BFc33oIrme1BF8z2oovkeHDpWTSmNntWNQVEYVZOImJBSai46h4Yv34Mqmu9BFc33oIrme1BF8z2oovkeHB6ckiZJkiRJkqR+LIwkSZIkSZLUj4XR3Du96AAa9nwPqmi+B1U034Mqmu9BFc33oIrme3AYcA0jSZIkSZIk9eMII0mSJEmSJPVjYSRJkiRJkqR+LIzmUERsHxEdETE5Ir5bdB4NfRFxZkQ8HxEP9bm2VERcFxGTSscPF5lRQ1tErBIR/4qIhyOiLSIOLV33faiKiIiFI+I/EXF/6T14bOn66hHx79LP5P+LiJFFZ9XQFhG1EXFvRFxROvc9qIqJiMcj4sGIuC8iJpSu+bNYFRMRS0bERRHRHhETI2IT34PDg4XRHIiIWuB3wA7AeGCfiBhfbCoNA2cD28907bvADSmlscANpXOpXGYAR6SUxgMbAweX/tvn+1CV8i6wdUppPeAjwPYRsTFwAnBKSmlN4BXgy8VF1DBxKDCxz7nvQVXaVimlj6SUmkvn/ixWJf0auDql1AisR/7voe/BYcDCaM5sBExOKXWmlKYD5wO7FJxJQ1xK6Rbg5Zku7wL8pfT4L8Culcyk4SWl9ExK6Z7S4zfIvxyshO9DVUjK3iydjih9JGBr4KLSdd+DKquIWBnYEfhz6TzwPaji+bNYFRERHwI2B84ASClNTym9iu/BYcHCaM6sBDzZ5/yp0jWp0pZLKT1TevwssFyRYTR8RMRqwPrAv/F9qAoqTQW6D3geuA54FHg1pTSj9BR/JqvcfgV8B+gunS+N70FVVgKujYi7I+Kg0jV/FqtSVgdeAM4qTc39c0Qsiu/BYcHCSBqkUkqJ/AuEVFYRsRhwMfDNlNLrfe/5PlS5pZS6UkofAVYmj/htLDaRhpOI2Al4PqV0d9FZNKxtllLagLw8xsERsXnfm/4sVpnVARsAf0gprQ+8xUzTz3wPDl0WRnPmaWCVPucrl65JlfZcRKwAUDo+X3AeDXERMYJcFp2bUrqkdNn3oSquNPz9X8AmwJIRUVe65c9kldOmwM4R8Th5SYKtyWt5+B5UxaSUni4dnwcuJZfn/ixWpTwFPJVS+nfp/CJygeR7cBiwMJoz/wXGlnbEGAnsDVxecCYNT5cD+5Ue7wf8o8AsGuJK63ScAUxMKZ3c55bvQ1VERIyOiCVLjxcBPkleS+tfwGdLT/M9qLJJKX0vpbRySmk18u9/N6aUPo/vQVVIRCwaEYv3PAY+BTyEP4tVISmlZ4EnI6KhdGkb4GF8Dw4LkUeP6YNExKfJc9hrgTNTSj8tNpGGuoj4O7AlsAzwHHA0cBlwATAGmALsmVKaeWFsaYGIiM2AW4EH6V274/vkdYx8H6rsImJd8kKateT/yXVBSunHEVFPHu2xFHAvsG9K6d3ikmo4iIgtgW+llHbyPahKKb3XLi2d1gHnpZR+GhFL489iVUhEfIS88P9IoBP4EqWfy/geHNIsjCRJkiRJktSPU9IkSZIkSZLUj4WRJEmSJEmS+rEwkiRJkiRJUj8WRpIkSZIkSerHwkiSJEmSJEn9WBhJkqSKiogUESf1Of9WRByzgL722RHx2QXxtT7gdfaIiIkR8a+Zrq8WEW9HxL2l+/+JiP373N85Ir5b7nyzyLtiRFxU6deVJEmDV13RASRJ0rDzLvCZiPhZSunFosP0iIi6lNKMOXz6l4EDU0q3zeLeoyml9Utfsx64JCIipXRWSuly4PIFFHmOpZSmAmUv0iRJ0tDhCCNJklRpM4DTgcNmvjHzCKGIeLN03DIibo6If0REZ0T8PCI+XxrB82BErNHny2wbERMi4pGI2Kn0+bUR8cuI+G9EPBARX+nzdW+NiMuBh2eRZ5/S138oIk4oXfsRsBlwRkT8cnbfaEqpEzgc+N/S5+4fEb/t873+ISLuKn1PW0bEmaWRSWf3yfCpiLgzIu6JiAsjYrHS9ccj4tjS9QcjorF0fYuIuK/0cW9ELF4a+fRQ6f7CEXFW6XPujYit+mS7JCKujohJEfGLPn92Z5f+DB6MiPf9c5MkSUOPI4wkSVIRfgc80FNKzKH1gHHAy0An8OeU0kYRcSjwDeCbpeetBmwErAH8KyLWBL4IvJZS2jAiFgJuj4hrS8/fAFg7pfRY3xeLiBWBE4CPAq8A10bErimlH0fE1sC3UkoT5iD3PUDjAPc+DGwC7EweebQp8D/AfyPiI8BTwA+AbVNKb0XEkeQC6selz38xpbRBRHwd+Fbpc78FHJxSur1ULr0z02seDKSU0jqlkunaiFirdO8jwPrkUWAdEfEbYFlgpZTS2qU/lyXn4HuWJEmDnCOMJElSxaWUXgf+SmnkzRz6b0rpmZTSu8CjQE/h8yC5JOpxQUqpO6U0iVwsNQKfAr4YEfcB/waWBsaWnv+fmcuikg2Bm1JKL5Smqp0LbD4XeXvEbO61ppRS6Xt4LqX0YEqpG2grfU8bA+PJBdd9wH7Aqn0+/5LS8W56/wxuB06OiP8FlpzFNLvNgHMAUkrtwBSgpzC6IaX0WkrpHfKIq1XJf4b1EfGbiNgeeH0uvndJkjRIOcJIkiQV5Vfk0Tdn9bk2g9L/0IqIGmBkn3vv9nnc3ee8m/6/06SZXieRS5tvpJSu6XsjIrYE3pqX8HNhfWDiAPf6fg8zf391QBdwXUppnw/4/K7S80kp/TwirgQ+TS6atuP9o4wG0jdDF1CXUnolItYDtgO+CuwJHDCHX0+SJA1SjjCSJEmFSCm9DFxAXkC6x+PkKWCQp2mNmIcvvUdE1JTWNaoHOoBrgK9FxAiAiFgrIhb9gK/zH2CLiFgmImqBfYCb5yZIRKwGnAj8Zi6/hx53AZuWptUREYv2mT420GuuURqpdALwX94/He5W4POl564FjCH/GQ309ZYBalJKF5Onx20wj9+LJEkaRBxhJEmSinQScEif8z8B/4iI+4GrmbfRP0+Qy54lgK+mlN6JiD+Tp2zdExEBvADsOrsvklJ6JiK+C/yLPELpypTSP+bg9deIiHuBhYE3gFNTSmfPw/dBSumFiNgf+Htp7SXIpc0js/m0b5YWsu6Z2nYVsEKf+78H/hARD5JHdO2fUno3/7HM0krAWaURXwDfm5fvRZIkDS6Rp81LkiRJkiRJmVPSJEmSJEmS1I+FkSRJkiRJkvqxMJIkSZIkSVI/FkaSJEmSJEnqx8JIkiRJkiRJ/VgYSZIkSZIkqR8LI0mSJEmSJPXz/wDPd9P2l4dQowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(list(rmse_dict.keys()),list(rmse_dict.values()),marker='o',ls=\"--\",color=\"b\",ms=4)\n",
    "plt.xlabel(\"Number of Dimensions\")\n",
    "plt.ylabel(\"Normalized RMSE\")\n",
    "plt.title(\"PCA\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
